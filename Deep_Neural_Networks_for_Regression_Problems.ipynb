{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Neural Networks for Regression Problems.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nidhaloff/House_prices_prediction_keras/blob/master/Deep_Neural_Networks_for_Regression_Problems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9QlV0BC_9PY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvdfBOX87gGV",
        "colab_type": "text"
      },
      "source": [
        "## First : Processing the dataset \n",
        "We will not go deep in processing the dataset, all we want to do is getting the dataset ready to be fed into our models .\n",
        "\n",
        "We will get rid of any features with missing values, then we will encode the categorical features, that's it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neKAXXozAmf9",
        "colab_type": "text"
      },
      "source": [
        "### Load the dataset :\n",
        "* Load train and test data into pandas DataFrames\n",
        "* Combine train and test data to process them together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeLRCvK6Au23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "    #get train data\n",
        "    train_data_path ='train.csv'\n",
        "    train = pd.read_csv(train_data_path)\n",
        "    \n",
        "    #get test data\n",
        "    test_data_path ='test.csv'\n",
        "    test = pd.read_csv(test_data_path)\n",
        "    \n",
        "    return train , test\n",
        "\n",
        "def get_combined_data():\n",
        "  #reading train data\n",
        "  train , test = get_data()\n",
        "\n",
        "  target = train.SalePrice\n",
        "  train.drop(['SalePrice'],axis = 1 , inplace = True)\n",
        "\n",
        "  combined = train.append(test)\n",
        "  combined.reset_index(inplace=True)\n",
        "  combined.drop(['index', 'Id'], inplace=True, axis=1)\n",
        "  return combined, target\n",
        "\n",
        "#Load train and test data into pandas DataFrames\n",
        "train_data, test_data = get_data()\n",
        "\n",
        "#Combine train and test data to process them together\n",
        "combined, target = get_combined_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPcvLGQGjWSr",
        "colab_type": "code",
        "outputId": "3f9a28c5-912c-41f7-f02a-def1dd04eaf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "combined.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>...</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2433.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2896.000000</td>\n",
              "      <td>2918.000000</td>\n",
              "      <td>2918.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2918.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "      <td>2919.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>57.137718</td>\n",
              "      <td>69.305795</td>\n",
              "      <td>10168.114080</td>\n",
              "      <td>6.089072</td>\n",
              "      <td>5.564577</td>\n",
              "      <td>1971.312778</td>\n",
              "      <td>1984.264474</td>\n",
              "      <td>102.201312</td>\n",
              "      <td>441.423235</td>\n",
              "      <td>49.582248</td>\n",
              "      <td>...</td>\n",
              "      <td>472.874572</td>\n",
              "      <td>93.709832</td>\n",
              "      <td>47.486811</td>\n",
              "      <td>23.098321</td>\n",
              "      <td>2.602261</td>\n",
              "      <td>16.062350</td>\n",
              "      <td>2.251799</td>\n",
              "      <td>50.825968</td>\n",
              "      <td>6.213087</td>\n",
              "      <td>2007.792737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>42.517628</td>\n",
              "      <td>23.344905</td>\n",
              "      <td>7886.996359</td>\n",
              "      <td>1.409947</td>\n",
              "      <td>1.113131</td>\n",
              "      <td>30.291442</td>\n",
              "      <td>20.894344</td>\n",
              "      <td>179.334253</td>\n",
              "      <td>455.610826</td>\n",
              "      <td>169.205611</td>\n",
              "      <td>...</td>\n",
              "      <td>215.394815</td>\n",
              "      <td>126.526589</td>\n",
              "      <td>67.575493</td>\n",
              "      <td>64.244246</td>\n",
              "      <td>25.188169</td>\n",
              "      <td>56.184365</td>\n",
              "      <td>35.663946</td>\n",
              "      <td>567.402211</td>\n",
              "      <td>2.714762</td>\n",
              "      <td>1.314964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7478.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1953.500000</td>\n",
              "      <td>1965.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>50.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>9453.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1993.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>368.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11570.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2001.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>733.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>190.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>1526.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1488.000000</td>\n",
              "      <td>1424.000000</td>\n",
              "      <td>742.000000</td>\n",
              "      <td>1012.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>800.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
              "count  2919.000000  2433.000000    2919.000000  2919.000000  2919.000000   \n",
              "mean     57.137718    69.305795   10168.114080     6.089072     5.564577   \n",
              "std      42.517628    23.344905    7886.996359     1.409947     1.113131   \n",
              "min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n",
              "25%      20.000000    59.000000    7478.000000     5.000000     5.000000   \n",
              "50%      50.000000    68.000000    9453.000000     6.000000     5.000000   \n",
              "75%      70.000000    80.000000   11570.000000     7.000000     6.000000   \n",
              "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
              "\n",
              "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  \\\n",
              "count  2919.000000   2919.000000  2896.000000  2918.000000  2918.000000   \n",
              "mean   1971.312778   1984.264474   102.201312   441.423235    49.582248   \n",
              "std      30.291442     20.894344   179.334253   455.610826   169.205611   \n",
              "min    1872.000000   1950.000000     0.000000     0.000000     0.000000   \n",
              "25%    1953.500000   1965.000000     0.000000     0.000000     0.000000   \n",
              "50%    1973.000000   1993.000000     0.000000   368.500000     0.000000   \n",
              "75%    2001.000000   2004.000000   164.000000   733.000000     0.000000   \n",
              "max    2010.000000   2010.000000  1600.000000  5644.000000  1526.000000   \n",
              "\n",
              "          ...        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch  \\\n",
              "count     ...       2918.000000  2919.000000  2919.000000    2919.000000   \n",
              "mean      ...        472.874572    93.709832    47.486811      23.098321   \n",
              "std       ...        215.394815   126.526589    67.575493      64.244246   \n",
              "min       ...          0.000000     0.000000     0.000000       0.000000   \n",
              "25%       ...        320.000000     0.000000     0.000000       0.000000   \n",
              "50%       ...        480.000000     0.000000    26.000000       0.000000   \n",
              "75%       ...        576.000000   168.000000    70.000000       0.000000   \n",
              "max       ...       1488.000000  1424.000000   742.000000    1012.000000   \n",
              "\n",
              "         3SsnPorch  ScreenPorch     PoolArea       MiscVal       MoSold  \\\n",
              "count  2919.000000  2919.000000  2919.000000   2919.000000  2919.000000   \n",
              "mean      2.602261    16.062350     2.251799     50.825968     6.213087   \n",
              "std      25.188169    56.184365    35.663946    567.402211     2.714762   \n",
              "min       0.000000     0.000000     0.000000      0.000000     1.000000   \n",
              "25%       0.000000     0.000000     0.000000      0.000000     4.000000   \n",
              "50%       0.000000     0.000000     0.000000      0.000000     6.000000   \n",
              "75%       0.000000     0.000000     0.000000      0.000000     8.000000   \n",
              "max     508.000000   576.000000   800.000000  17000.000000    12.000000   \n",
              "\n",
              "            YrSold  \n",
              "count  2919.000000  \n",
              "mean   2007.792737  \n",
              "std       1.314964  \n",
              "min    2006.000000  \n",
              "25%    2007.000000  \n",
              "50%    2008.000000  \n",
              "75%    2009.000000  \n",
              "max    2010.000000  \n",
              "\n",
              "[8 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL7U515m9BXQ",
        "colab_type": "text"
      },
      "source": [
        "let's define a function to get the columns that don't have any missing values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwHRdGTD9YRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cols_with_no_nans(df,col_type):\n",
        "    '''\n",
        "    Arguments :\n",
        "    df : The dataframe to process\n",
        "    col_type : \n",
        "          num : to only get numerical columns with no nans\n",
        "          no_num : to only get nun-numerical columns with no nans\n",
        "          all : to get any columns with no nans    \n",
        "    '''\n",
        "    if (col_type == 'num'):\n",
        "        predictors = df.select_dtypes(exclude=['object'])\n",
        "    elif (col_type == 'no_num'):\n",
        "        predictors = df.select_dtypes(include=['object'])\n",
        "    elif (col_type == 'all'):\n",
        "        predictors = df\n",
        "    else :\n",
        "        print('Error : choose a type (num, no_num, all)')\n",
        "        return 0\n",
        "    cols_with_no_nans = []\n",
        "    for col in predictors.columns:\n",
        "        if not df[col].isnull().any():\n",
        "            cols_with_no_nans.append(col)\n",
        "    return cols_with_no_nans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkdPBeu1n2Se",
        "colab_type": "text"
      },
      "source": [
        "Get the columns that do not have any missing values ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdH1rGZFjNL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cols = get_cols_with_no_nans(combined , 'num')\n",
        "cat_cols = get_cols_with_no_nans(combined , 'no_num')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frf_IY8Onvqm",
        "colab_type": "text"
      },
      "source": [
        "Let's see how many columns we got"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X295Nvfl5ZO",
        "colab_type": "code",
        "outputId": "dfbd9718-5863-40a4-f830-74256fe90916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print ('Number of numerical columns with no nan values :',len(num_cols))\n",
        "print ('Number of nun-numerical columns with no nan values :',len(cat_cols))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of numerical columns with no nan values : 25\n",
            "Number of nun-numerical columns with no nan values : 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11f-e_7dmhRq",
        "colab_type": "code",
        "outputId": "749a6e60-60ee-4f25-c098-ccecfbd6500e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "source": [
        "combined = combined[num_cols + cat_cols]\n",
        "combined.hist(figsize = (12,10))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAJNCAYAAADOCphkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERERMQiDc8iIiIiIhb9H1Yx5T4+ddTFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4324acbda0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N793AWuKeS7v",
        "colab_type": "text"
      },
      "source": [
        "**The correlation between the features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ_lUgcCodbD",
        "colab_type": "code",
        "outputId": "b29c7658-7e5a-45ce-e8c1-1baa821db42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        }
      },
      "source": [
        "train_data = train_data[num_cols + cat_cols]\n",
        "train_data['Target'] = target\n",
        "\n",
        "C_mat = train_data.corr()\n",
        "fig = plt.figure(figsize = (15,15))\n",
        "\n",
        "sb.heatmap(C_mat, vmax = .8, square = True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAANCCAYAAADiKrTgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0mtm44gUJAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f43275525f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2A_bc2tqLf7",
        "colab_type": "text"
      },
      "source": [
        "From the correlation heatmap above, we see that about 15 features are highly correlated with the target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV0ziidQqnE3",
        "colab_type": "text"
      },
      "source": [
        "**One Hot Encode The Categorical Features :**\n",
        "\n",
        "We will encode the categorical features using one hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo2ZI9barWSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def oneHotEncode(df,colNames):\n",
        "    for col in colNames:\n",
        "        if( df[col].dtype == np.dtype('object')):\n",
        "            dummies = pd.get_dummies(df[col],prefix=col)\n",
        "            df = pd.concat([df,dummies],axis=1)\n",
        "\n",
        "            #drop the encoded column\n",
        "            df.drop([col],axis = 1 , inplace=True)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng_BSoDwrr3G",
        "colab_type": "code",
        "outputId": "cdf0407d-53b0-471a-be38-126b6d5ef9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print('There were {} columns before encoding categorical features'.format(combined.shape[1]))\n",
        "combined = oneHotEncode(combined, cat_cols)\n",
        "print('There are {} columns after encoding categorical features'.format(combined.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There were 45 columns before encoding categorical features\n",
            "There are 149 columns after encoding categorical features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MosRPZPEtEgt",
        "colab_type": "text"
      },
      "source": [
        "Now, split back combined dataFrame to training data and test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INvgC50TtPmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_combined():\n",
        "    global combined\n",
        "    train = combined[:1460]\n",
        "    test = combined[1460:]\n",
        "\n",
        "    return train , test "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZL6rBHUtYDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = split_combined()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPKYTh4wtinr",
        "colab_type": "text"
      },
      "source": [
        "## Second : Make the Deep Neural Network\n",
        " * Define a sequential model\n",
        " * Add some dense layers\n",
        " * Use '**relu**' as the activation function in the hidden layers\n",
        " * Use a '**normal**' initializer as the kernal_intializer \n",
        "           Initializers define the way to set the initial random weights of Keras layers.\n",
        " * We will use mean_absolute_error as a loss function\n",
        " * Define the output layer with only one node\n",
        " * Use 'linear 'as the activation function for the output layer\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsJsrFlIvmzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NN_model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrZVKcMbwCcI",
        "colab_type": "text"
      },
      "source": [
        "**The Input Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILFBftZnvqFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6RW_lRRwG2i",
        "colab_type": "text"
      },
      "source": [
        "**The Hidden Layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz61h9vLv7xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHSMp0zJwKRc",
        "colab_type": "text"
      },
      "source": [
        "**The Output Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9v_kTrsv-38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHpg10glxNam",
        "colab_type": "text"
      },
      "source": [
        "**Compile the network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROXr07cAv-pW",
        "colab_type": "code",
        "outputId": "53125c94-37d9-4033-bde1-c6c696f3a955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "NN_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               19200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 184,065\n",
            "Trainable params: 184,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMirCFkrxUA8",
        "colab_type": "text"
      },
      "source": [
        "**Define a checkpoint callback :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4kZNz7HxafP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYgT8VgWxicp",
        "colab_type": "text"
      },
      "source": [
        "## Third : Train the model :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGEt2nCHzMZ0",
        "colab_type": "code",
        "outputId": "c9cf6641-4141-4aef-979e-19e4e207bd64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36437
        }
      },
      "source": [
        "NN_model.fit(train, target, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 19251.8903 - mean_absolute_error: 19251.8903 - val_loss: 23041.8968 - val_mean_absolute_error: 23041.8968\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 21730.93555\n",
            "Epoch 2/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 18180.4985 - mean_absolute_error: 18180.4985 - val_loss: 22197.7991 - val_mean_absolute_error: 22197.7991\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 21730.93555\n",
            "Epoch 3/500\n",
            "1168/1168 [==============================] - 0s 247us/step - loss: 19741.2386 - mean_absolute_error: 19741.2386 - val_loss: 25841.9880 - val_mean_absolute_error: 25841.9880\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 21730.93555\n",
            "Epoch 4/500\n",
            "1168/1168 [==============================] - 0s 246us/step - loss: 18684.5058 - mean_absolute_error: 18684.5058 - val_loss: 21956.6884 - val_mean_absolute_error: 21956.6884\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 21730.93555\n",
            "Epoch 5/500\n",
            "1168/1168 [==============================] - 0s 248us/step - loss: 18341.4664 - mean_absolute_error: 18341.4664 - val_loss: 21861.6464 - val_mean_absolute_error: 21861.6464\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 21730.93555\n",
            "Epoch 6/500\n",
            "1168/1168 [==============================] - 0s 258us/step - loss: 17354.8412 - mean_absolute_error: 17354.8412 - val_loss: 25254.1994 - val_mean_absolute_error: 25254.1994\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 21730.93555\n",
            "Epoch 7/500\n",
            "1168/1168 [==============================] - 0s 251us/step - loss: 21426.4028 - mean_absolute_error: 21426.4028 - val_loss: 22443.0247 - val_mean_absolute_error: 22443.0247\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 21730.93555\n",
            "Epoch 8/500\n",
            "1168/1168 [==============================] - 0s 242us/step - loss: 18516.6611 - mean_absolute_error: 18516.6611 - val_loss: 23000.5402 - val_mean_absolute_error: 23000.5402\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 21730.93555\n",
            "Epoch 9/500\n",
            "1168/1168 [==============================] - 0s 245us/step - loss: 17095.7704 - mean_absolute_error: 17095.7704 - val_loss: 24209.5742 - val_mean_absolute_error: 24209.5742\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 21730.93555\n",
            "Epoch 10/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 18065.2426 - mean_absolute_error: 18065.2426 - val_loss: 24260.8016 - val_mean_absolute_error: 24260.8016\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 21730.93555\n",
            "Epoch 11/500\n",
            "1168/1168 [==============================] - 0s 293us/step - loss: 20168.5724 - mean_absolute_error: 20168.5724 - val_loss: 21647.6836 - val_mean_absolute_error: 21647.6836\n",
            "\n",
            "Epoch 00011: val_loss improved from 21730.93555 to 21647.68365, saving model to Weights-011--21647.68365.hdf5\n",
            "Epoch 12/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 17825.2654 - mean_absolute_error: 17825.2654 - val_loss: 25051.3828 - val_mean_absolute_error: 25051.3828\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 21647.68365\n",
            "Epoch 13/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 18563.5240 - mean_absolute_error: 18563.5240 - val_loss: 25259.1912 - val_mean_absolute_error: 25259.1912\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 21647.68365\n",
            "Epoch 14/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 17093.0236 - mean_absolute_error: 17093.0236 - val_loss: 26828.2004 - val_mean_absolute_error: 26828.2004\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 21647.68365\n",
            "Epoch 15/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 18249.9339 - mean_absolute_error: 18249.9339 - val_loss: 23246.7289 - val_mean_absolute_error: 23246.7289\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 21647.68365\n",
            "Epoch 16/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 18147.5923 - mean_absolute_error: 18147.5923 - val_loss: 22332.3597 - val_mean_absolute_error: 22332.3597\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 21647.68365\n",
            "Epoch 17/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 19856.6229 - mean_absolute_error: 19856.6229 - val_loss: 23471.6422 - val_mean_absolute_error: 23471.6422\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 21647.68365\n",
            "Epoch 18/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 18217.4503 - mean_absolute_error: 18217.4503 - val_loss: 22122.8741 - val_mean_absolute_error: 22122.8741\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 21647.68365\n",
            "Epoch 19/500\n",
            "1168/1168 [==============================] - 0s 265us/step - loss: 17347.3431 - mean_absolute_error: 17347.3431 - val_loss: 23147.7859 - val_mean_absolute_error: 23147.7859\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 21647.68365\n",
            "Epoch 20/500\n",
            "1168/1168 [==============================] - 0s 262us/step - loss: 19854.8931 - mean_absolute_error: 19854.8931 - val_loss: 25120.5798 - val_mean_absolute_error: 25120.5798\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 21647.68365\n",
            "Epoch 21/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 17539.2162 - mean_absolute_error: 17539.2162 - val_loss: 24668.4968 - val_mean_absolute_error: 24668.4968\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 21647.68365\n",
            "Epoch 22/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 18277.7967 - mean_absolute_error: 18277.7967 - val_loss: 24538.7988 - val_mean_absolute_error: 24538.7988\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 21647.68365\n",
            "Epoch 23/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 17592.7188 - mean_absolute_error: 17592.7188 - val_loss: 22379.1071 - val_mean_absolute_error: 22379.1071\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 21647.68365\n",
            "Epoch 24/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 16513.9946 - mean_absolute_error: 16513.9946 - val_loss: 22856.0307 - val_mean_absolute_error: 22856.0307\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 21647.68365\n",
            "Epoch 25/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 18986.1813 - mean_absolute_error: 18986.1813 - val_loss: 21821.0856 - val_mean_absolute_error: 21821.0856\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 21647.68365\n",
            "Epoch 26/500\n",
            "1168/1168 [==============================] - 0s 288us/step - loss: 18317.5925 - mean_absolute_error: 18317.5925 - val_loss: 22838.6445 - val_mean_absolute_error: 22838.6445\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 21647.68365\n",
            "Epoch 27/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 18058.4383 - mean_absolute_error: 18058.4383 - val_loss: 23065.4212 - val_mean_absolute_error: 23065.4212\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 21647.68365\n",
            "Epoch 28/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 17857.8225 - mean_absolute_error: 17857.8225 - val_loss: 22595.3132 - val_mean_absolute_error: 22595.3132\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 21647.68365\n",
            "Epoch 29/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 16800.8333 - mean_absolute_error: 16800.8333 - val_loss: 23487.0708 - val_mean_absolute_error: 23487.0708\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 21647.68365\n",
            "Epoch 30/500\n",
            "1168/1168 [==============================] - 0s 290us/step - loss: 17977.4838 - mean_absolute_error: 17977.4838 - val_loss: 24813.5311 - val_mean_absolute_error: 24813.5311\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 21647.68365\n",
            "Epoch 31/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 17059.4557 - mean_absolute_error: 17059.4557 - val_loss: 22348.5519 - val_mean_absolute_error: 22348.5519\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 21647.68365\n",
            "Epoch 32/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 17715.1148 - mean_absolute_error: 17715.1148 - val_loss: 22796.2697 - val_mean_absolute_error: 22796.2697\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 21647.68365\n",
            "Epoch 33/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 17587.0544 - mean_absolute_error: 17587.0544 - val_loss: 22271.1262 - val_mean_absolute_error: 22271.1262\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 21647.68365\n",
            "Epoch 34/500\n",
            "1168/1168 [==============================] - 0s 309us/step - loss: 16938.2339 - mean_absolute_error: 16938.2339 - val_loss: 23119.4070 - val_mean_absolute_error: 23119.4070\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 21647.68365\n",
            "Epoch 35/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 16428.9159 - mean_absolute_error: 16428.9159 - val_loss: 22421.9985 - val_mean_absolute_error: 22421.9985\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 21647.68365\n",
            "Epoch 36/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 19348.5488 - mean_absolute_error: 19348.5488 - val_loss: 23493.4349 - val_mean_absolute_error: 23493.4349\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 21647.68365\n",
            "Epoch 37/500\n",
            "1168/1168 [==============================] - 0s 288us/step - loss: 16561.5584 - mean_absolute_error: 16561.5584 - val_loss: 21951.4439 - val_mean_absolute_error: 21951.4439\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 21647.68365\n",
            "Epoch 38/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 17115.5760 - mean_absolute_error: 17115.5760 - val_loss: 22299.7604 - val_mean_absolute_error: 22299.7604\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 21647.68365\n",
            "Epoch 39/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 16685.2633 - mean_absolute_error: 16685.2633 - val_loss: 23135.0874 - val_mean_absolute_error: 23135.0874\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 21647.68365\n",
            "Epoch 40/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 16317.0102 - mean_absolute_error: 16317.0102 - val_loss: 24054.8953 - val_mean_absolute_error: 24054.8953\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 21647.68365\n",
            "Epoch 41/500\n",
            "1168/1168 [==============================] - 0s 291us/step - loss: 17568.7947 - mean_absolute_error: 17568.7947 - val_loss: 28301.1942 - val_mean_absolute_error: 28301.1942\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 21647.68365\n",
            "Epoch 42/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 17062.1087 - mean_absolute_error: 17062.1087 - val_loss: 22290.1346 - val_mean_absolute_error: 22290.1346\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 21647.68365\n",
            "Epoch 43/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 16691.0535 - mean_absolute_error: 16691.0535 - val_loss: 21925.1461 - val_mean_absolute_error: 21925.1461\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 21647.68365\n",
            "Epoch 44/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 18089.5901 - mean_absolute_error: 18089.5901 - val_loss: 21148.5133 - val_mean_absolute_error: 21148.5133\n",
            "\n",
            "Epoch 00044: val_loss improved from 21647.68365 to 21148.51327, saving model to Weights-044--21148.51327.hdf5\n",
            "Epoch 45/500\n",
            "1168/1168 [==============================] - 0s 292us/step - loss: 16037.1326 - mean_absolute_error: 16037.1326 - val_loss: 22690.0533 - val_mean_absolute_error: 22690.0533\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 21148.51327\n",
            "Epoch 46/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 16712.0206 - mean_absolute_error: 16712.0206 - val_loss: 22802.5435 - val_mean_absolute_error: 22802.5435\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 21148.51327\n",
            "Epoch 47/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 17711.9521 - mean_absolute_error: 17711.9521 - val_loss: 25963.7243 - val_mean_absolute_error: 25963.7243\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 21148.51327\n",
            "Epoch 48/500\n",
            "1168/1168 [==============================] - 0s 293us/step - loss: 17406.7884 - mean_absolute_error: 17406.7884 - val_loss: 21808.7077 - val_mean_absolute_error: 21808.7077\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 21148.51327\n",
            "Epoch 49/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 17026.8352 - mean_absolute_error: 17026.8352 - val_loss: 28835.5540 - val_mean_absolute_error: 28835.5540\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 21148.51327\n",
            "Epoch 50/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 18845.1215 - mean_absolute_error: 18845.1215 - val_loss: 30004.3135 - val_mean_absolute_error: 30004.3135\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 21148.51327\n",
            "Epoch 51/500\n",
            "1168/1168 [==============================] - 0s 261us/step - loss: 18775.7980 - mean_absolute_error: 18775.7980 - val_loss: 23389.1513 - val_mean_absolute_error: 23389.1513\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 21148.51327\n",
            "Epoch 52/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 16653.0475 - mean_absolute_error: 16653.0475 - val_loss: 22066.2332 - val_mean_absolute_error: 22066.2332\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 21148.51327\n",
            "Epoch 53/500\n",
            "1168/1168 [==============================] - 0s 263us/step - loss: 16774.1630 - mean_absolute_error: 16774.1630 - val_loss: 21619.4331 - val_mean_absolute_error: 21619.4331\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 21148.51327\n",
            "Epoch 54/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 16825.0505 - mean_absolute_error: 16825.0505 - val_loss: 24446.2778 - val_mean_absolute_error: 24446.2778\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 21148.51327\n",
            "Epoch 55/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 16426.2571 - mean_absolute_error: 16426.2571 - val_loss: 23800.1518 - val_mean_absolute_error: 23800.1518\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 21148.51327\n",
            "Epoch 56/500\n",
            "1168/1168 [==============================] - 0s 294us/step - loss: 16485.7143 - mean_absolute_error: 16485.7143 - val_loss: 22356.1978 - val_mean_absolute_error: 22356.1978\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 21148.51327\n",
            "Epoch 57/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 17009.0480 - mean_absolute_error: 17009.0480 - val_loss: 21942.5870 - val_mean_absolute_error: 21942.5870\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 21148.51327\n",
            "Epoch 58/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 17620.9739 - mean_absolute_error: 17620.9739 - val_loss: 29365.1832 - val_mean_absolute_error: 29365.1832\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 21148.51327\n",
            "Epoch 59/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 16553.0687 - mean_absolute_error: 16553.0687 - val_loss: 21087.5454 - val_mean_absolute_error: 21087.5454\n",
            "\n",
            "Epoch 00059: val_loss improved from 21148.51327 to 21087.54543, saving model to Weights-059--21087.54543.hdf5\n",
            "Epoch 60/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 16417.8271 - mean_absolute_error: 16417.8271 - val_loss: 25568.3565 - val_mean_absolute_error: 25568.3565\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 21087.54543\n",
            "Epoch 61/500\n",
            "1168/1168 [==============================] - 0s 262us/step - loss: 17617.9713 - mean_absolute_error: 17617.9713 - val_loss: 24998.6282 - val_mean_absolute_error: 24998.6282\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 21087.54543\n",
            "Epoch 62/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 17928.5605 - mean_absolute_error: 17928.5605 - val_loss: 22127.3398 - val_mean_absolute_error: 22127.3398\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 21087.54543\n",
            "Epoch 63/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 18444.5536 - mean_absolute_error: 18444.5536 - val_loss: 23373.8050 - val_mean_absolute_error: 23373.8050\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 21087.54543\n",
            "Epoch 64/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 17553.4588 - mean_absolute_error: 17553.4588 - val_loss: 22860.2387 - val_mean_absolute_error: 22860.2387\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 21087.54543\n",
            "Epoch 65/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 18745.3646 - mean_absolute_error: 18745.3646 - val_loss: 23679.5027 - val_mean_absolute_error: 23679.5027\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 21087.54543\n",
            "Epoch 66/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 16493.8333 - mean_absolute_error: 16493.8333 - val_loss: 23028.9527 - val_mean_absolute_error: 23028.9527\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 21087.54543\n",
            "Epoch 67/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 16285.4621 - mean_absolute_error: 16285.4621 - val_loss: 23921.5161 - val_mean_absolute_error: 23921.5161\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 21087.54543\n",
            "Epoch 68/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 17284.1359 - mean_absolute_error: 17284.1359 - val_loss: 25695.5797 - val_mean_absolute_error: 25695.5797\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 21087.54543\n",
            "Epoch 69/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 16202.3844 - mean_absolute_error: 16202.3844 - val_loss: 21001.6445 - val_mean_absolute_error: 21001.6445\n",
            "\n",
            "Epoch 00069: val_loss improved from 21087.54543 to 21001.64448, saving model to Weights-069--21001.64448.hdf5\n",
            "Epoch 70/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 17205.7211 - mean_absolute_error: 17205.7211 - val_loss: 21430.8015 - val_mean_absolute_error: 21430.8015\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 21001.64448\n",
            "Epoch 71/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 17880.6389 - mean_absolute_error: 17880.6389 - val_loss: 25848.1113 - val_mean_absolute_error: 25848.1113\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 21001.64448\n",
            "Epoch 72/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 16893.2566 - mean_absolute_error: 16893.2566 - val_loss: 22381.1741 - val_mean_absolute_error: 22381.1741\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 21001.64448\n",
            "Epoch 73/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 16570.5691 - mean_absolute_error: 16570.5691 - val_loss: 22041.0476 - val_mean_absolute_error: 22041.0476\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 21001.64448\n",
            "Epoch 74/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 16454.8047 - mean_absolute_error: 16454.8047 - val_loss: 21808.7369 - val_mean_absolute_error: 21808.7369\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 21001.64448\n",
            "Epoch 75/500\n",
            "1168/1168 [==============================] - 0s 291us/step - loss: 17046.4743 - mean_absolute_error: 17046.4743 - val_loss: 22670.7589 - val_mean_absolute_error: 22670.7589\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 21001.64448\n",
            "Epoch 76/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 16195.2430 - mean_absolute_error: 16195.2430 - val_loss: 23028.9686 - val_mean_absolute_error: 23028.9686\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 21001.64448\n",
            "Epoch 77/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 16241.8650 - mean_absolute_error: 16241.8650 - val_loss: 21414.5600 - val_mean_absolute_error: 21414.5600\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 21001.64448\n",
            "Epoch 78/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 16401.3261 - mean_absolute_error: 16401.3261 - val_loss: 21449.5040 - val_mean_absolute_error: 21449.5040\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 21001.64448\n",
            "Epoch 79/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 16353.9384 - mean_absolute_error: 16353.9384 - val_loss: 27273.3029 - val_mean_absolute_error: 27273.3029\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 21001.64448\n",
            "Epoch 80/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 18499.6800 - mean_absolute_error: 18499.6800 - val_loss: 24203.0284 - val_mean_absolute_error: 24203.0284\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 21001.64448\n",
            "Epoch 81/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 16552.5120 - mean_absolute_error: 16552.5120 - val_loss: 21810.0816 - val_mean_absolute_error: 21810.0816\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 21001.64448\n",
            "Epoch 82/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 15660.3926 - mean_absolute_error: 15660.3926 - val_loss: 21363.1732 - val_mean_absolute_error: 21363.1732\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 21001.64448\n",
            "Epoch 83/500\n",
            "1168/1168 [==============================] - 0s 290us/step - loss: 17095.6191 - mean_absolute_error: 17095.6191 - val_loss: 21224.7029 - val_mean_absolute_error: 21224.7029\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 21001.64448\n",
            "Epoch 84/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 17477.1955 - mean_absolute_error: 17477.1955 - val_loss: 25271.2818 - val_mean_absolute_error: 25271.2818\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 21001.64448\n",
            "Epoch 85/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 16149.6175 - mean_absolute_error: 16149.6175 - val_loss: 26160.3853 - val_mean_absolute_error: 26160.3853\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 21001.64448\n",
            "Epoch 86/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 17225.4758 - mean_absolute_error: 17225.4758 - val_loss: 23246.2904 - val_mean_absolute_error: 23246.2904\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 21001.64448\n",
            "Epoch 87/500\n",
            "1168/1168 [==============================] - 0s 291us/step - loss: 16242.1760 - mean_absolute_error: 16242.1760 - val_loss: 26128.9572 - val_mean_absolute_error: 26128.9572\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 21001.64448\n",
            "Epoch 88/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 18415.0085 - mean_absolute_error: 18415.0085 - val_loss: 23875.6387 - val_mean_absolute_error: 23875.6387\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 21001.64448\n",
            "Epoch 89/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 17536.2410 - mean_absolute_error: 17536.2410 - val_loss: 20974.1807 - val_mean_absolute_error: 20974.1807\n",
            "\n",
            "Epoch 00089: val_loss improved from 21001.64448 to 20974.18070, saving model to Weights-089--20974.18070.hdf5\n",
            "Epoch 90/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 17793.3271 - mean_absolute_error: 17793.3271 - val_loss: 22824.3458 - val_mean_absolute_error: 22824.3458\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 20974.18070\n",
            "Epoch 91/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 16632.7065 - mean_absolute_error: 16632.7065 - val_loss: 21521.8776 - val_mean_absolute_error: 21521.8776\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 20974.18070\n",
            "Epoch 92/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 16242.9290 - mean_absolute_error: 16242.9290 - val_loss: 22158.8075 - val_mean_absolute_error: 22158.8075\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 20974.18070\n",
            "Epoch 93/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 15936.2677 - mean_absolute_error: 15936.2677 - val_loss: 20905.1412 - val_mean_absolute_error: 20905.1412\n",
            "\n",
            "Epoch 00093: val_loss improved from 20974.18070 to 20905.14121, saving model to Weights-093--20905.14121.hdf5\n",
            "Epoch 94/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 15386.3000 - mean_absolute_error: 15386.3000 - val_loss: 21253.7174 - val_mean_absolute_error: 21253.7174\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 20905.14121\n",
            "Epoch 95/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 16775.7677 - mean_absolute_error: 16775.7677 - val_loss: 21499.5849 - val_mean_absolute_error: 21499.5849\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 20905.14121\n",
            "Epoch 96/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 16673.7562 - mean_absolute_error: 16673.7562 - val_loss: 24621.5807 - val_mean_absolute_error: 24621.5807\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 20905.14121\n",
            "Epoch 97/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 16873.7530 - mean_absolute_error: 16873.7530 - val_loss: 21213.3169 - val_mean_absolute_error: 21213.3169\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 20905.14121\n",
            "Epoch 98/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 16097.6535 - mean_absolute_error: 16097.6535 - val_loss: 26615.6155 - val_mean_absolute_error: 26615.6155\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 20905.14121\n",
            "Epoch 99/500\n",
            "1168/1168 [==============================] - 0s 264us/step - loss: 17136.7997 - mean_absolute_error: 17136.7997 - val_loss: 22287.2505 - val_mean_absolute_error: 22287.2505\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 20905.14121\n",
            "Epoch 100/500\n",
            "1168/1168 [==============================] - 0s 263us/step - loss: 15847.8140 - mean_absolute_error: 15847.8140 - val_loss: 20945.0525 - val_mean_absolute_error: 20945.0525\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 20905.14121\n",
            "Epoch 101/500\n",
            "1168/1168 [==============================] - 0s 264us/step - loss: 15835.2661 - mean_absolute_error: 15835.2661 - val_loss: 23739.8973 - val_mean_absolute_error: 23739.8973\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 20905.14121\n",
            "Epoch 102/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 17096.0136 - mean_absolute_error: 17096.0136 - val_loss: 22328.8600 - val_mean_absolute_error: 22328.8600\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 20905.14121\n",
            "Epoch 103/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 15793.5507 - mean_absolute_error: 15793.5507 - val_loss: 22022.6656 - val_mean_absolute_error: 22022.6656\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 20905.14121\n",
            "Epoch 104/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 16678.9522 - mean_absolute_error: 16678.9522 - val_loss: 25772.0967 - val_mean_absolute_error: 25772.0967\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 20905.14121\n",
            "Epoch 105/500\n",
            "1168/1168 [==============================] - 0s 265us/step - loss: 16062.3658 - mean_absolute_error: 16062.3658 - val_loss: 20618.1137 - val_mean_absolute_error: 20618.1137\n",
            "\n",
            "Epoch 00105: val_loss improved from 20905.14121 to 20618.11371, saving model to Weights-105--20618.11371.hdf5\n",
            "Epoch 106/500\n",
            "1168/1168 [==============================] - 0s 297us/step - loss: 16293.5891 - mean_absolute_error: 16293.5891 - val_loss: 21930.7954 - val_mean_absolute_error: 21930.7954\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 20618.11371\n",
            "Epoch 107/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 16442.0719 - mean_absolute_error: 16442.0719 - val_loss: 21350.8516 - val_mean_absolute_error: 21350.8516\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 20618.11371\n",
            "Epoch 108/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 16790.3279 - mean_absolute_error: 16790.3279 - val_loss: 22684.3137 - val_mean_absolute_error: 22684.3137\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 20618.11371\n",
            "Epoch 109/500\n",
            "1168/1168 [==============================] - 0s 290us/step - loss: 15969.6260 - mean_absolute_error: 15969.6260 - val_loss: 21631.6737 - val_mean_absolute_error: 21631.6737\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 20618.11371\n",
            "Epoch 110/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 15910.9959 - mean_absolute_error: 15910.9959 - val_loss: 21947.3767 - val_mean_absolute_error: 21947.3767\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 20618.11371\n",
            "Epoch 111/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 16220.4947 - mean_absolute_error: 16220.4947 - val_loss: 21064.1396 - val_mean_absolute_error: 21064.1396\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 20618.11371\n",
            "Epoch 112/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 16980.9767 - mean_absolute_error: 16980.9767 - val_loss: 21489.1696 - val_mean_absolute_error: 21489.1696\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 20618.11371\n",
            "Epoch 113/500\n",
            "1168/1168 [==============================] - 0s 288us/step - loss: 18929.1497 - mean_absolute_error: 18929.1497 - val_loss: 25739.1385 - val_mean_absolute_error: 25739.1385\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 20618.11371\n",
            "Epoch 114/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 19762.8182 - mean_absolute_error: 19762.8182 - val_loss: 21104.6741 - val_mean_absolute_error: 21104.6741\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 20618.11371\n",
            "Epoch 115/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 18105.3445 - mean_absolute_error: 18105.3445 - val_loss: 29053.6816 - val_mean_absolute_error: 29053.6816\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 20618.11371\n",
            "Epoch 116/500\n",
            "1168/1168 [==============================] - 0s 260us/step - loss: 16399.1279 - mean_absolute_error: 16399.1279 - val_loss: 21171.2132 - val_mean_absolute_error: 21171.2132\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 20618.11371\n",
            "Epoch 117/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 17086.9897 - mean_absolute_error: 17086.9897 - val_loss: 22476.8738 - val_mean_absolute_error: 22476.8738\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 20618.11371\n",
            "Epoch 118/500\n",
            "1168/1168 [==============================] - 0s 261us/step - loss: 17338.6136 - mean_absolute_error: 17338.6136 - val_loss: 21315.7704 - val_mean_absolute_error: 21315.7704\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 20618.11371\n",
            "Epoch 119/500\n",
            "1168/1168 [==============================] - 0s 264us/step - loss: 17673.8352 - mean_absolute_error: 17673.8352 - val_loss: 22508.1642 - val_mean_absolute_error: 22508.1642\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 20618.11371\n",
            "Epoch 120/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 15697.5798 - mean_absolute_error: 15697.5798 - val_loss: 22326.9274 - val_mean_absolute_error: 22326.9274\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 20618.11371\n",
            "Epoch 121/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 15748.6639 - mean_absolute_error: 15748.6639 - val_loss: 21893.0580 - val_mean_absolute_error: 21893.0580\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 20618.11371\n",
            "Epoch 122/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 16722.8824 - mean_absolute_error: 16722.8824 - val_loss: 21846.0028 - val_mean_absolute_error: 21846.0028\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 20618.11371\n",
            "Epoch 123/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 15778.7157 - mean_absolute_error: 15778.7157 - val_loss: 21232.3708 - val_mean_absolute_error: 21232.3708\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 20618.11371\n",
            "Epoch 124/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 18545.1070 - mean_absolute_error: 18545.1070 - val_loss: 22014.4804 - val_mean_absolute_error: 22014.4804\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 20618.11371\n",
            "Epoch 125/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 16015.2765 - mean_absolute_error: 16015.2765 - val_loss: 21317.1205 - val_mean_absolute_error: 21317.1205\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 20618.11371\n",
            "Epoch 126/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 17237.6435 - mean_absolute_error: 17237.6435 - val_loss: 21470.1063 - val_mean_absolute_error: 21470.1063\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 20618.11371\n",
            "Epoch 127/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 18233.2756 - mean_absolute_error: 18233.2756 - val_loss: 20651.4546 - val_mean_absolute_error: 20651.4546\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 20618.11371\n",
            "Epoch 128/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 19115.5114 - mean_absolute_error: 19115.5114 - val_loss: 21596.1607 - val_mean_absolute_error: 21596.1607\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 20618.11371\n",
            "Epoch 129/500\n",
            "1168/1168 [==============================] - 0s 290us/step - loss: 16980.9750 - mean_absolute_error: 16980.9750 - val_loss: 21564.7179 - val_mean_absolute_error: 21564.7179\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 20618.11371\n",
            "Epoch 130/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 17319.7951 - mean_absolute_error: 17319.7951 - val_loss: 23317.4062 - val_mean_absolute_error: 23317.4062\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 20618.11371\n",
            "Epoch 131/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 17649.6655 - mean_absolute_error: 17649.6655 - val_loss: 21542.6320 - val_mean_absolute_error: 21542.6320\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 20618.11371\n",
            "Epoch 132/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 15804.2263 - mean_absolute_error: 15804.2263 - val_loss: 20532.8797 - val_mean_absolute_error: 20532.8797\n",
            "\n",
            "Epoch 00132: val_loss improved from 20618.11371 to 20532.87966, saving model to Weights-132--20532.87966.hdf5\n",
            "Epoch 133/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 15332.3753 - mean_absolute_error: 15332.3753 - val_loss: 21874.1336 - val_mean_absolute_error: 21874.1336\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 20532.87966\n",
            "Epoch 134/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 16682.6714 - mean_absolute_error: 16682.6714 - val_loss: 21911.8328 - val_mean_absolute_error: 21911.8328\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 20532.87966\n",
            "Epoch 135/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 18574.5602 - mean_absolute_error: 18574.5602 - val_loss: 24223.5007 - val_mean_absolute_error: 24223.5007\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 20532.87966\n",
            "Epoch 136/500\n",
            "1168/1168 [==============================] - 0s 295us/step - loss: 16881.6453 - mean_absolute_error: 16881.6453 - val_loss: 20607.8657 - val_mean_absolute_error: 20607.8657\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 20532.87966\n",
            "Epoch 137/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 16578.9287 - mean_absolute_error: 16578.9287 - val_loss: 23873.6021 - val_mean_absolute_error: 23873.6021\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 20532.87966\n",
            "Epoch 138/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 16961.4053 - mean_absolute_error: 16961.4053 - val_loss: 21087.0553 - val_mean_absolute_error: 21087.0553\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 20532.87966\n",
            "Epoch 139/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 15186.4133 - mean_absolute_error: 15186.4133 - val_loss: 21075.9403 - val_mean_absolute_error: 21075.9403\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 20532.87966\n",
            "Epoch 140/500\n",
            "1168/1168 [==============================] - 0s 294us/step - loss: 17557.4414 - mean_absolute_error: 17557.4414 - val_loss: 28307.2941 - val_mean_absolute_error: 28307.2941\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 20532.87966\n",
            "Epoch 141/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 17307.1182 - mean_absolute_error: 17307.1182 - val_loss: 21342.3390 - val_mean_absolute_error: 21342.3390\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 20532.87966\n",
            "Epoch 142/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 17764.5555 - mean_absolute_error: 17764.5555 - val_loss: 22155.2970 - val_mean_absolute_error: 22155.2970\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 20532.87966\n",
            "Epoch 143/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 16715.9580 - mean_absolute_error: 16715.9580 - val_loss: 22614.5912 - val_mean_absolute_error: 22614.5912\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 20532.87966\n",
            "Epoch 144/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 16695.1586 - mean_absolute_error: 16695.1586 - val_loss: 20831.6667 - val_mean_absolute_error: 20831.6667\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 20532.87966\n",
            "Epoch 145/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 16719.9547 - mean_absolute_error: 16719.9547 - val_loss: 23207.9970 - val_mean_absolute_error: 23207.9970\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 20532.87966\n",
            "Epoch 146/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 16610.8736 - mean_absolute_error: 16610.8736 - val_loss: 20541.3054 - val_mean_absolute_error: 20541.3054\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 20532.87966\n",
            "Epoch 147/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 16283.4162 - mean_absolute_error: 16283.4162 - val_loss: 21051.6126 - val_mean_absolute_error: 21051.6126\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 20532.87966\n",
            "Epoch 148/500\n",
            "1168/1168 [==============================] - 0s 294us/step - loss: 16182.5241 - mean_absolute_error: 16182.5241 - val_loss: 20591.9435 - val_mean_absolute_error: 20591.9435\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 20532.87966\n",
            "Epoch 149/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 15476.7333 - mean_absolute_error: 15476.7333 - val_loss: 20989.3851 - val_mean_absolute_error: 20989.3851\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 20532.87966\n",
            "Epoch 150/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 15768.9830 - mean_absolute_error: 15768.9830 - val_loss: 22500.6333 - val_mean_absolute_error: 22500.6333\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 20532.87966\n",
            "Epoch 151/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 18337.8202 - mean_absolute_error: 18337.8202 - val_loss: 26741.7179 - val_mean_absolute_error: 26741.7179\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 20532.87966\n",
            "Epoch 152/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 16957.4680 - mean_absolute_error: 16957.4680 - val_loss: 21307.6722 - val_mean_absolute_error: 21307.6722\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 20532.87966\n",
            "Epoch 153/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 15613.5138 - mean_absolute_error: 15613.5138 - val_loss: 21493.6289 - val_mean_absolute_error: 21493.6289\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 20532.87966\n",
            "Epoch 154/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 16167.6438 - mean_absolute_error: 16167.6438 - val_loss: 23836.9060 - val_mean_absolute_error: 23836.9060\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 20532.87966\n",
            "Epoch 155/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 15864.3175 - mean_absolute_error: 15864.3175 - val_loss: 21696.8161 - val_mean_absolute_error: 21696.8161\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 20532.87966\n",
            "Epoch 156/500\n",
            "1168/1168 [==============================] - 0s 264us/step - loss: 17528.6746 - mean_absolute_error: 17528.6746 - val_loss: 25927.1836 - val_mean_absolute_error: 25927.1836\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 20532.87966\n",
            "Epoch 157/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 16588.9097 - mean_absolute_error: 16588.9097 - val_loss: 22010.3057 - val_mean_absolute_error: 22010.3057\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 20532.87966\n",
            "Epoch 158/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 15576.9634 - mean_absolute_error: 15576.9634 - val_loss: 29342.0984 - val_mean_absolute_error: 29342.0984\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 20532.87966\n",
            "Epoch 159/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 18974.2139 - mean_absolute_error: 18974.2139 - val_loss: 24652.2637 - val_mean_absolute_error: 24652.2637\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 20532.87966\n",
            "Epoch 160/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 16243.1605 - mean_absolute_error: 16243.1605 - val_loss: 21082.0082 - val_mean_absolute_error: 21082.0082\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 20532.87966\n",
            "Epoch 161/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 15792.5051 - mean_absolute_error: 15792.5051 - val_loss: 22654.8261 - val_mean_absolute_error: 22654.8261\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 20532.87966\n",
            "Epoch 162/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 15333.7935 - mean_absolute_error: 15333.7935 - val_loss: 21831.5394 - val_mean_absolute_error: 21831.5394\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 20532.87966\n",
            "Epoch 163/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 16252.8411 - mean_absolute_error: 16252.8411 - val_loss: 20079.4667 - val_mean_absolute_error: 20079.4667\n",
            "\n",
            "Epoch 00163: val_loss improved from 20532.87966 to 20079.46672, saving model to Weights-163--20079.46672.hdf5\n",
            "Epoch 164/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 15946.9134 - mean_absolute_error: 15946.9134 - val_loss: 35180.6499 - val_mean_absolute_error: 35180.6499\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 20079.46672\n",
            "Epoch 165/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 17325.0878 - mean_absolute_error: 17325.0878 - val_loss: 21221.8511 - val_mean_absolute_error: 21221.8511\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 20079.46672\n",
            "Epoch 166/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 17288.8208 - mean_absolute_error: 17288.8208 - val_loss: 22123.5644 - val_mean_absolute_error: 22123.5644\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 20079.46672\n",
            "Epoch 167/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 15922.0854 - mean_absolute_error: 15922.0854 - val_loss: 21643.3200 - val_mean_absolute_error: 21643.3200\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 20079.46672\n",
            "Epoch 168/500\n",
            "1168/1168 [==============================] - 0s 265us/step - loss: 15723.1226 - mean_absolute_error: 15723.1226 - val_loss: 21105.3778 - val_mean_absolute_error: 21105.3778\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 20079.46672\n",
            "Epoch 169/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 19409.7802 - mean_absolute_error: 19409.7802 - val_loss: 21622.2277 - val_mean_absolute_error: 21622.2277\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 20079.46672\n",
            "Epoch 170/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 17358.6441 - mean_absolute_error: 17358.6441 - val_loss: 21855.0804 - val_mean_absolute_error: 21855.0804\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 20079.46672\n",
            "Epoch 171/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 15264.9671 - mean_absolute_error: 15264.9671 - val_loss: 21297.8083 - val_mean_absolute_error: 21297.8083\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 20079.46672\n",
            "Epoch 172/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 14997.6990 - mean_absolute_error: 14997.6990 - val_loss: 22231.6375 - val_mean_absolute_error: 22231.6375\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 20079.46672\n",
            "Epoch 173/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 16590.9148 - mean_absolute_error: 16590.9148 - val_loss: 21270.5931 - val_mean_absolute_error: 21270.5931\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 20079.46672\n",
            "Epoch 174/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 15143.1370 - mean_absolute_error: 15143.1370 - val_loss: 21382.4669 - val_mean_absolute_error: 21382.4669\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 20079.46672\n",
            "Epoch 175/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 16251.7482 - mean_absolute_error: 16251.7482 - val_loss: 24460.4441 - val_mean_absolute_error: 24460.4441\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 20079.46672\n",
            "Epoch 176/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 16088.7376 - mean_absolute_error: 16088.7376 - val_loss: 23002.8851 - val_mean_absolute_error: 23002.8851\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 20079.46672\n",
            "Epoch 177/500\n",
            "1168/1168 [==============================] - 0s 263us/step - loss: 16705.6507 - mean_absolute_error: 16705.6507 - val_loss: 24089.3484 - val_mean_absolute_error: 24089.3484\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 20079.46672\n",
            "Epoch 178/500\n",
            "1168/1168 [==============================] - 0s 292us/step - loss: 19301.4696 - mean_absolute_error: 19301.4696 - val_loss: 28140.3828 - val_mean_absolute_error: 28140.3828\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 20079.46672\n",
            "Epoch 179/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 15704.3949 - mean_absolute_error: 15704.3949 - val_loss: 22606.3557 - val_mean_absolute_error: 22606.3557\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 20079.46672\n",
            "Epoch 180/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 14848.1599 - mean_absolute_error: 14848.1599 - val_loss: 20502.4660 - val_mean_absolute_error: 20502.4660\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 20079.46672\n",
            "Epoch 181/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 15538.3431 - mean_absolute_error: 15538.3431 - val_loss: 21695.6016 - val_mean_absolute_error: 21695.6016\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 20079.46672\n",
            "Epoch 182/500\n",
            "1168/1168 [==============================] - 0s 292us/step - loss: 16219.0795 - mean_absolute_error: 16219.0795 - val_loss: 21837.8378 - val_mean_absolute_error: 21837.8378\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 20079.46672\n",
            "Epoch 183/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 16736.1129 - mean_absolute_error: 16736.1129 - val_loss: 21048.0112 - val_mean_absolute_error: 21048.0112\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 20079.46672\n",
            "Epoch 184/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 16914.3489 - mean_absolute_error: 16914.3489 - val_loss: 27795.8507 - val_mean_absolute_error: 27795.8507\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 20079.46672\n",
            "Epoch 185/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 16183.1400 - mean_absolute_error: 16183.1400 - val_loss: 20534.7215 - val_mean_absolute_error: 20534.7215\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 20079.46672\n",
            "Epoch 186/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 16253.2238 - mean_absolute_error: 16253.2238 - val_loss: 24046.3423 - val_mean_absolute_error: 24046.3423\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 20079.46672\n",
            "Epoch 187/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 16030.5789 - mean_absolute_error: 16030.5789 - val_loss: 20655.8560 - val_mean_absolute_error: 20655.8560\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 20079.46672\n",
            "Epoch 188/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 15960.8433 - mean_absolute_error: 15960.8433 - val_loss: 22553.7541 - val_mean_absolute_error: 22553.7541\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 20079.46672\n",
            "Epoch 189/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 16456.2696 - mean_absolute_error: 16456.2696 - val_loss: 20919.8556 - val_mean_absolute_error: 20919.8556\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 20079.46672\n",
            "Epoch 190/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 15413.5016 - mean_absolute_error: 15413.5016 - val_loss: 21058.1058 - val_mean_absolute_error: 21058.1058\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 20079.46672\n",
            "Epoch 191/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 15176.5420 - mean_absolute_error: 15176.5420 - val_loss: 21765.4898 - val_mean_absolute_error: 21765.4898\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 20079.46672\n",
            "Epoch 192/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 15360.4633 - mean_absolute_error: 15360.4633 - val_loss: 20514.5649 - val_mean_absolute_error: 20514.5649\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 20079.46672\n",
            "Epoch 193/500\n",
            "1168/1168 [==============================] - 0s 294us/step - loss: 19721.4537 - mean_absolute_error: 19721.4537 - val_loss: 31663.1579 - val_mean_absolute_error: 31663.1579\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 20079.46672\n",
            "Epoch 194/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 16816.8613 - mean_absolute_error: 16816.8613 - val_loss: 20677.4157 - val_mean_absolute_error: 20677.4157\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 20079.46672\n",
            "Epoch 195/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 15700.2227 - mean_absolute_error: 15700.2227 - val_loss: 21010.8764 - val_mean_absolute_error: 21010.8764\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 20079.46672\n",
            "Epoch 196/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 14970.3983 - mean_absolute_error: 14970.3983 - val_loss: 20794.1739 - val_mean_absolute_error: 20794.1739\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 20079.46672\n",
            "Epoch 197/500\n",
            "1168/1168 [==============================] - 0s 295us/step - loss: 15704.7232 - mean_absolute_error: 15704.7232 - val_loss: 20444.9075 - val_mean_absolute_error: 20444.9075\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 20079.46672\n",
            "Epoch 198/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 15304.5635 - mean_absolute_error: 15304.5635 - val_loss: 24328.6474 - val_mean_absolute_error: 24328.6474\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 20079.46672\n",
            "Epoch 199/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 16254.6459 - mean_absolute_error: 16254.6459 - val_loss: 21833.6249 - val_mean_absolute_error: 21833.6249\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 20079.46672\n",
            "Epoch 200/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 15347.5794 - mean_absolute_error: 15347.5794 - val_loss: 21717.5076 - val_mean_absolute_error: 21717.5076\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 20079.46672\n",
            "Epoch 201/500\n",
            "1168/1168 [==============================] - 0s 294us/step - loss: 15947.2442 - mean_absolute_error: 15947.2442 - val_loss: 20115.1699 - val_mean_absolute_error: 20115.1699\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 20079.46672\n",
            "Epoch 202/500\n",
            "1168/1168 [==============================] - 0s 262us/step - loss: 15708.7055 - mean_absolute_error: 15708.7055 - val_loss: 26313.0057 - val_mean_absolute_error: 26313.0057\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 20079.46672\n",
            "Epoch 203/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 17343.9783 - mean_absolute_error: 17343.9783 - val_loss: 25041.9947 - val_mean_absolute_error: 25041.9947\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 20079.46672\n",
            "Epoch 204/500\n",
            "1168/1168 [==============================] - 0s 265us/step - loss: 16764.0706 - mean_absolute_error: 16764.0706 - val_loss: 21032.0376 - val_mean_absolute_error: 21032.0376\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 20079.46672\n",
            "Epoch 205/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 15985.6848 - mean_absolute_error: 15985.6848 - val_loss: 26414.3311 - val_mean_absolute_error: 26414.3311\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 20079.46672\n",
            "Epoch 206/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 17090.4812 - mean_absolute_error: 17090.4812 - val_loss: 27504.3836 - val_mean_absolute_error: 27504.3836\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 20079.46672\n",
            "Epoch 207/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 18129.4739 - mean_absolute_error: 18129.4739 - val_loss: 24356.4449 - val_mean_absolute_error: 24356.4449\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 20079.46672\n",
            "Epoch 208/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 15872.0911 - mean_absolute_error: 15872.0911 - val_loss: 23965.7650 - val_mean_absolute_error: 23965.7650\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 20079.46672\n",
            "Epoch 209/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 16723.6706 - mean_absolute_error: 16723.6706 - val_loss: 22600.2028 - val_mean_absolute_error: 22600.2028\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 20079.46672\n",
            "Epoch 210/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 15324.4957 - mean_absolute_error: 15324.4957 - val_loss: 21795.6444 - val_mean_absolute_error: 21795.6444\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 20079.46672\n",
            "Epoch 211/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 15585.3378 - mean_absolute_error: 15585.3378 - val_loss: 21032.1701 - val_mean_absolute_error: 21032.1701\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 20079.46672\n",
            "Epoch 212/500\n",
            "1168/1168 [==============================] - 0s 295us/step - loss: 14936.5973 - mean_absolute_error: 14936.5973 - val_loss: 20837.0482 - val_mean_absolute_error: 20837.0482\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 20079.46672\n",
            "Epoch 213/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 15018.8663 - mean_absolute_error: 15018.8663 - val_loss: 21389.7227 - val_mean_absolute_error: 21389.7227\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 20079.46672\n",
            "Epoch 214/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 16776.5050 - mean_absolute_error: 16776.5050 - val_loss: 23241.4283 - val_mean_absolute_error: 23241.4283\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 20079.46672\n",
            "Epoch 215/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 15471.2855 - mean_absolute_error: 15471.2855 - val_loss: 20991.3145 - val_mean_absolute_error: 20991.3145\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 20079.46672\n",
            "Epoch 216/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 15687.6893 - mean_absolute_error: 15687.6893 - val_loss: 20898.7765 - val_mean_absolute_error: 20898.7765\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 20079.46672\n",
            "Epoch 217/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 15731.8834 - mean_absolute_error: 15731.8834 - val_loss: 20961.9159 - val_mean_absolute_error: 20961.9159\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 20079.46672\n",
            "Epoch 218/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 15057.7222 - mean_absolute_error: 15057.7222 - val_loss: 24752.3417 - val_mean_absolute_error: 24752.3417\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 20079.46672\n",
            "Epoch 219/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 15593.1127 - mean_absolute_error: 15593.1127 - val_loss: 22939.5457 - val_mean_absolute_error: 22939.5457\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 20079.46672\n",
            "Epoch 220/500\n",
            "1168/1168 [==============================] - 0s 288us/step - loss: 16537.7096 - mean_absolute_error: 16537.7096 - val_loss: 23405.0972 - val_mean_absolute_error: 23405.0972\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 20079.46672\n",
            "Epoch 221/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 15155.1686 - mean_absolute_error: 15155.1686 - val_loss: 20219.6874 - val_mean_absolute_error: 20219.6874\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 20079.46672\n",
            "Epoch 222/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 14960.5200 - mean_absolute_error: 14960.5200 - val_loss: 22392.2849 - val_mean_absolute_error: 22392.2849\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 20079.46672\n",
            "Epoch 223/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 15722.6579 - mean_absolute_error: 15722.6579 - val_loss: 21842.2011 - val_mean_absolute_error: 21842.2011\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 20079.46672\n",
            "Epoch 224/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 14840.1789 - mean_absolute_error: 14840.1789 - val_loss: 22846.9730 - val_mean_absolute_error: 22846.9730\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 20079.46672\n",
            "Epoch 225/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 19366.2804 - mean_absolute_error: 19366.2804 - val_loss: 25947.8463 - val_mean_absolute_error: 25947.8463\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 20079.46672\n",
            "Epoch 226/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 14776.6613 - mean_absolute_error: 14776.6613 - val_loss: 24746.2910 - val_mean_absolute_error: 24746.2910\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 20079.46672\n",
            "Epoch 227/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 16140.3689 - mean_absolute_error: 16140.3689 - val_loss: 20233.2281 - val_mean_absolute_error: 20233.2281\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 20079.46672\n",
            "Epoch 228/500\n",
            "1168/1168 [==============================] - 0s 292us/step - loss: 15325.0132 - mean_absolute_error: 15325.0132 - val_loss: 20661.0890 - val_mean_absolute_error: 20661.0890\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 20079.46672\n",
            "Epoch 229/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 15645.9813 - mean_absolute_error: 15645.9813 - val_loss: 22594.4185 - val_mean_absolute_error: 22594.4185\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 20079.46672\n",
            "Epoch 230/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 15790.6727 - mean_absolute_error: 15790.6727 - val_loss: 20778.1926 - val_mean_absolute_error: 20778.1926\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 20079.46672\n",
            "Epoch 231/500\n",
            "1168/1168 [==============================] - 0s 290us/step - loss: 14550.1088 - mean_absolute_error: 14550.1088 - val_loss: 21778.7052 - val_mean_absolute_error: 21778.7052\n",
            "\n",
            "Epoch 00231: val_loss did not improve from 20079.46672\n",
            "Epoch 232/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 15712.6760 - mean_absolute_error: 15712.6760 - val_loss: 21119.3993 - val_mean_absolute_error: 21119.3993\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 20079.46672\n",
            "Epoch 233/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 14753.5261 - mean_absolute_error: 14753.5261 - val_loss: 21505.3056 - val_mean_absolute_error: 21505.3056\n",
            "\n",
            "Epoch 00233: val_loss did not improve from 20079.46672\n",
            "Epoch 234/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 16935.3979 - mean_absolute_error: 16935.3979 - val_loss: 21213.8052 - val_mean_absolute_error: 21213.8052\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 20079.46672\n",
            "Epoch 235/500\n",
            "1168/1168 [==============================] - 0s 295us/step - loss: 15410.2371 - mean_absolute_error: 15410.2371 - val_loss: 21642.2092 - val_mean_absolute_error: 21642.2092\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 20079.46672\n",
            "Epoch 236/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 16333.0912 - mean_absolute_error: 16333.0912 - val_loss: 20587.1284 - val_mean_absolute_error: 20587.1284\n",
            "\n",
            "Epoch 00236: val_loss did not improve from 20079.46672\n",
            "Epoch 237/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 15312.1969 - mean_absolute_error: 15312.1969 - val_loss: 20691.2347 - val_mean_absolute_error: 20691.2347\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 20079.46672\n",
            "Epoch 238/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 15241.6045 - mean_absolute_error: 15241.6045 - val_loss: 21414.1914 - val_mean_absolute_error: 21414.1914\n",
            "\n",
            "Epoch 00238: val_loss did not improve from 20079.46672\n",
            "Epoch 239/500\n",
            "1168/1168 [==============================] - 0s 305us/step - loss: 14603.2903 - mean_absolute_error: 14603.2903 - val_loss: 22107.0167 - val_mean_absolute_error: 22107.0167\n",
            "\n",
            "Epoch 00239: val_loss did not improve from 20079.46672\n",
            "Epoch 240/500\n",
            "1168/1168 [==============================] - 0s 294us/step - loss: 15033.3180 - mean_absolute_error: 15033.3180 - val_loss: 20399.6230 - val_mean_absolute_error: 20399.6230\n",
            "\n",
            "Epoch 00240: val_loss did not improve from 20079.46672\n",
            "Epoch 241/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 15483.8465 - mean_absolute_error: 15483.8465 - val_loss: 20628.2187 - val_mean_absolute_error: 20628.2187\n",
            "\n",
            "Epoch 00241: val_loss did not improve from 20079.46672\n",
            "Epoch 242/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 15513.5578 - mean_absolute_error: 15513.5578 - val_loss: 21566.1906 - val_mean_absolute_error: 21566.1906\n",
            "\n",
            "Epoch 00242: val_loss did not improve from 20079.46672\n",
            "Epoch 243/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 16252.0902 - mean_absolute_error: 16252.0902 - val_loss: 21346.5161 - val_mean_absolute_error: 21346.5161\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 20079.46672\n",
            "Epoch 244/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 15022.1871 - mean_absolute_error: 15022.1871 - val_loss: 23583.6073 - val_mean_absolute_error: 23583.6073\n",
            "\n",
            "Epoch 00244: val_loss did not improve from 20079.46672\n",
            "Epoch 245/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 14916.9149 - mean_absolute_error: 14916.9149 - val_loss: 20958.4548 - val_mean_absolute_error: 20958.4548\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 20079.46672\n",
            "Epoch 246/500\n",
            "1168/1168 [==============================] - 0s 303us/step - loss: 14612.7860 - mean_absolute_error: 14612.7860 - val_loss: 20494.5654 - val_mean_absolute_error: 20494.5654\n",
            "\n",
            "Epoch 00246: val_loss did not improve from 20079.46672\n",
            "Epoch 247/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 17093.2349 - mean_absolute_error: 17093.2349 - val_loss: 27875.8312 - val_mean_absolute_error: 27875.8312\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 20079.46672\n",
            "Epoch 248/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 16963.3494 - mean_absolute_error: 16963.3494 - val_loss: 21625.4861 - val_mean_absolute_error: 21625.4861\n",
            "\n",
            "Epoch 00248: val_loss did not improve from 20079.46672\n",
            "Epoch 249/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 14374.7666 - mean_absolute_error: 14374.7666 - val_loss: 24031.0700 - val_mean_absolute_error: 24031.0700\n",
            "\n",
            "Epoch 00249: val_loss did not improve from 20079.46672\n",
            "Epoch 250/500\n",
            "1168/1168 [==============================] - 0s 292us/step - loss: 15424.0088 - mean_absolute_error: 15424.0088 - val_loss: 20541.1875 - val_mean_absolute_error: 20541.1875\n",
            "\n",
            "Epoch 00250: val_loss did not improve from 20079.46672\n",
            "Epoch 251/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 15202.7697 - mean_absolute_error: 15202.7697 - val_loss: 21715.8509 - val_mean_absolute_error: 21715.8509\n",
            "\n",
            "Epoch 00251: val_loss did not improve from 20079.46672\n",
            "Epoch 252/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 16273.0852 - mean_absolute_error: 16273.0852 - val_loss: 21355.5109 - val_mean_absolute_error: 21355.5109\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 20079.46672\n",
            "Epoch 253/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 15951.6743 - mean_absolute_error: 15951.6743 - val_loss: 20583.7594 - val_mean_absolute_error: 20583.7594\n",
            "\n",
            "Epoch 00253: val_loss did not improve from 20079.46672\n",
            "Epoch 254/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 14611.8985 - mean_absolute_error: 14611.8985 - val_loss: 20412.6721 - val_mean_absolute_error: 20412.6721\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 20079.46672\n",
            "Epoch 255/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 14379.8960 - mean_absolute_error: 14379.8960 - val_loss: 20868.8836 - val_mean_absolute_error: 20868.8836\n",
            "\n",
            "Epoch 00255: val_loss did not improve from 20079.46672\n",
            "Epoch 256/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 14742.9510 - mean_absolute_error: 14742.9510 - val_loss: 23167.8397 - val_mean_absolute_error: 23167.8397\n",
            "\n",
            "Epoch 00256: val_loss did not improve from 20079.46672\n",
            "Epoch 257/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 15030.2156 - mean_absolute_error: 15030.2156 - val_loss: 20460.7020 - val_mean_absolute_error: 20460.7020\n",
            "\n",
            "Epoch 00257: val_loss did not improve from 20079.46672\n",
            "Epoch 258/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 15356.6419 - mean_absolute_error: 15356.6419 - val_loss: 23726.9441 - val_mean_absolute_error: 23726.9441\n",
            "\n",
            "Epoch 00258: val_loss did not improve from 20079.46672\n",
            "Epoch 259/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 14904.2351 - mean_absolute_error: 14904.2351 - val_loss: 21116.4218 - val_mean_absolute_error: 21116.4218\n",
            "\n",
            "Epoch 00259: val_loss did not improve from 20079.46672\n",
            "Epoch 260/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 14621.9823 - mean_absolute_error: 14621.9823 - val_loss: 20028.8854 - val_mean_absolute_error: 20028.8854\n",
            "\n",
            "Epoch 00260: val_loss improved from 20079.46672 to 20028.88543, saving model to Weights-260--20028.88543.hdf5\n",
            "Epoch 261/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 14938.8709 - mean_absolute_error: 14938.8709 - val_loss: 20893.3474 - val_mean_absolute_error: 20893.3474\n",
            "\n",
            "Epoch 00261: val_loss did not improve from 20028.88543\n",
            "Epoch 262/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 15959.8394 - mean_absolute_error: 15959.8394 - val_loss: 22770.9837 - val_mean_absolute_error: 22770.9837\n",
            "\n",
            "Epoch 00262: val_loss did not improve from 20028.88543\n",
            "Epoch 263/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 17444.0184 - mean_absolute_error: 17444.0184 - val_loss: 20503.8980 - val_mean_absolute_error: 20503.8980\n",
            "\n",
            "Epoch 00263: val_loss did not improve from 20028.88543\n",
            "Epoch 264/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 16331.0200 - mean_absolute_error: 16331.0200 - val_loss: 20589.7032 - val_mean_absolute_error: 20589.7032\n",
            "\n",
            "Epoch 00264: val_loss did not improve from 20028.88543\n",
            "Epoch 265/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 15907.2234 - mean_absolute_error: 15907.2234 - val_loss: 20945.2613 - val_mean_absolute_error: 20945.2613\n",
            "\n",
            "Epoch 00265: val_loss did not improve from 20028.88543\n",
            "Epoch 266/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 16861.7369 - mean_absolute_error: 16861.7369 - val_loss: 21102.1501 - val_mean_absolute_error: 21102.1501\n",
            "\n",
            "Epoch 00266: val_loss did not improve from 20028.88543\n",
            "Epoch 267/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 15909.7228 - mean_absolute_error: 15909.7228 - val_loss: 20602.0975 - val_mean_absolute_error: 20602.0975\n",
            "\n",
            "Epoch 00267: val_loss did not improve from 20028.88543\n",
            "Epoch 268/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 15102.4394 - mean_absolute_error: 15102.4394 - val_loss: 20535.5757 - val_mean_absolute_error: 20535.5757\n",
            "\n",
            "Epoch 00268: val_loss did not improve from 20028.88543\n",
            "Epoch 269/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 15765.9180 - mean_absolute_error: 15765.9180 - val_loss: 23836.5135 - val_mean_absolute_error: 23836.5135\n",
            "\n",
            "Epoch 00269: val_loss did not improve from 20028.88543\n",
            "Epoch 270/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 15903.4399 - mean_absolute_error: 15903.4399 - val_loss: 22601.5721 - val_mean_absolute_error: 22601.5721\n",
            "\n",
            "Epoch 00270: val_loss did not improve from 20028.88543\n",
            "Epoch 271/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 14847.9558 - mean_absolute_error: 14847.9558 - val_loss: 22727.0731 - val_mean_absolute_error: 22727.0731\n",
            "\n",
            "Epoch 00271: val_loss did not improve from 20028.88543\n",
            "Epoch 272/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 14545.5239 - mean_absolute_error: 14545.5239 - val_loss: 19612.3344 - val_mean_absolute_error: 19612.3344\n",
            "\n",
            "Epoch 00272: val_loss improved from 20028.88543 to 19612.33439, saving model to Weights-272--19612.33439.hdf5\n",
            "Epoch 273/500\n",
            "1168/1168 [==============================] - 0s 290us/step - loss: 15392.1297 - mean_absolute_error: 15392.1297 - val_loss: 25692.6000 - val_mean_absolute_error: 25692.6000\n",
            "\n",
            "Epoch 00273: val_loss did not improve from 19612.33439\n",
            "Epoch 274/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 17684.3005 - mean_absolute_error: 17684.3005 - val_loss: 22942.4775 - val_mean_absolute_error: 22942.4775\n",
            "\n",
            "Epoch 00274: val_loss did not improve from 19612.33439\n",
            "Epoch 275/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 16139.9274 - mean_absolute_error: 16139.9274 - val_loss: 21030.2041 - val_mean_absolute_error: 21030.2041\n",
            "\n",
            "Epoch 00275: val_loss did not improve from 19612.33439\n",
            "Epoch 276/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 15242.2808 - mean_absolute_error: 15242.2808 - val_loss: 20175.6176 - val_mean_absolute_error: 20175.6176\n",
            "\n",
            "Epoch 00276: val_loss did not improve from 19612.33439\n",
            "Epoch 277/500\n",
            "1168/1168 [==============================] - 0s 296us/step - loss: 14547.2876 - mean_absolute_error: 14547.2876 - val_loss: 25045.7423 - val_mean_absolute_error: 25045.7423\n",
            "\n",
            "Epoch 00277: val_loss did not improve from 19612.33439\n",
            "Epoch 278/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 15199.7319 - mean_absolute_error: 15199.7319 - val_loss: 20420.6087 - val_mean_absolute_error: 20420.6087\n",
            "\n",
            "Epoch 00278: val_loss did not improve from 19612.33439\n",
            "Epoch 279/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 15554.4667 - mean_absolute_error: 15554.4667 - val_loss: 25492.2331 - val_mean_absolute_error: 25492.2331\n",
            "\n",
            "Epoch 00279: val_loss did not improve from 19612.33439\n",
            "Epoch 280/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 14721.4725 - mean_absolute_error: 14721.4725 - val_loss: 21696.0801 - val_mean_absolute_error: 21696.0801\n",
            "\n",
            "Epoch 00280: val_loss did not improve from 19612.33439\n",
            "Epoch 281/500\n",
            "1168/1168 [==============================] - 0s 302us/step - loss: 14619.7761 - mean_absolute_error: 14619.7761 - val_loss: 23954.1478 - val_mean_absolute_error: 23954.1478\n",
            "\n",
            "Epoch 00281: val_loss did not improve from 19612.33439\n",
            "Epoch 282/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 15100.9883 - mean_absolute_error: 15100.9883 - val_loss: 20268.5835 - val_mean_absolute_error: 20268.5835\n",
            "\n",
            "Epoch 00282: val_loss did not improve from 19612.33439\n",
            "Epoch 283/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 14338.7377 - mean_absolute_error: 14338.7377 - val_loss: 21028.5085 - val_mean_absolute_error: 21028.5085\n",
            "\n",
            "Epoch 00283: val_loss did not improve from 19612.33439\n",
            "Epoch 284/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 15811.7244 - mean_absolute_error: 15811.7244 - val_loss: 20183.0011 - val_mean_absolute_error: 20183.0011\n",
            "\n",
            "Epoch 00284: val_loss did not improve from 19612.33439\n",
            "Epoch 285/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 13877.9486 - mean_absolute_error: 13877.9486 - val_loss: 21106.9173 - val_mean_absolute_error: 21106.9173\n",
            "\n",
            "Epoch 00285: val_loss did not improve from 19612.33439\n",
            "Epoch 286/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 15454.0077 - mean_absolute_error: 15454.0077 - val_loss: 21653.8728 - val_mean_absolute_error: 21653.8728\n",
            "\n",
            "Epoch 00286: val_loss did not improve from 19612.33439\n",
            "Epoch 287/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 15344.3940 - mean_absolute_error: 15344.3940 - val_loss: 21351.8426 - val_mean_absolute_error: 21351.8426\n",
            "\n",
            "Epoch 00287: val_loss did not improve from 19612.33439\n",
            "Epoch 288/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 16633.9905 - mean_absolute_error: 16633.9905 - val_loss: 23224.2249 - val_mean_absolute_error: 23224.2249\n",
            "\n",
            "Epoch 00288: val_loss did not improve from 19612.33439\n",
            "Epoch 289/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 16151.1022 - mean_absolute_error: 16151.1022 - val_loss: 24287.6931 - val_mean_absolute_error: 24287.6931\n",
            "\n",
            "Epoch 00289: val_loss did not improve from 19612.33439\n",
            "Epoch 290/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 17581.0579 - mean_absolute_error: 17581.0579 - val_loss: 23421.2472 - val_mean_absolute_error: 23421.2472\n",
            "\n",
            "Epoch 00290: val_loss did not improve from 19612.33439\n",
            "Epoch 291/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 14408.9379 - mean_absolute_error: 14408.9379 - val_loss: 21128.7467 - val_mean_absolute_error: 21128.7467\n",
            "\n",
            "Epoch 00291: val_loss did not improve from 19612.33439\n",
            "Epoch 292/500\n",
            "1168/1168 [==============================] - 0s 314us/step - loss: 14867.8302 - mean_absolute_error: 14867.8302 - val_loss: 22221.1277 - val_mean_absolute_error: 22221.1277\n",
            "\n",
            "Epoch 00292: val_loss did not improve from 19612.33439\n",
            "Epoch 293/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 14772.5298 - mean_absolute_error: 14772.5298 - val_loss: 21622.3081 - val_mean_absolute_error: 21622.3081\n",
            "\n",
            "Epoch 00293: val_loss did not improve from 19612.33439\n",
            "Epoch 294/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 15272.8901 - mean_absolute_error: 15272.8901 - val_loss: 21727.5551 - val_mean_absolute_error: 21727.5551\n",
            "\n",
            "Epoch 00294: val_loss did not improve from 19612.33439\n",
            "Epoch 295/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 14533.0456 - mean_absolute_error: 14533.0456 - val_loss: 22659.5618 - val_mean_absolute_error: 22659.5618\n",
            "\n",
            "Epoch 00295: val_loss did not improve from 19612.33439\n",
            "Epoch 296/500\n",
            "1168/1168 [==============================] - 0s 291us/step - loss: 15423.5624 - mean_absolute_error: 15423.5624 - val_loss: 20807.8710 - val_mean_absolute_error: 20807.8710\n",
            "\n",
            "Epoch 00296: val_loss did not improve from 19612.33439\n",
            "Epoch 297/500\n",
            "1168/1168 [==============================] - 0s 295us/step - loss: 15049.2972 - mean_absolute_error: 15049.2972 - val_loss: 22480.4618 - val_mean_absolute_error: 22480.4618\n",
            "\n",
            "Epoch 00297: val_loss did not improve from 19612.33439\n",
            "Epoch 298/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 14674.7211 - mean_absolute_error: 14674.7211 - val_loss: 21341.2910 - val_mean_absolute_error: 21341.2910\n",
            "\n",
            "Epoch 00298: val_loss did not improve from 19612.33439\n",
            "Epoch 299/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 15092.2350 - mean_absolute_error: 15092.2350 - val_loss: 21009.7926 - val_mean_absolute_error: 21009.7926\n",
            "\n",
            "Epoch 00299: val_loss did not improve from 19612.33439\n",
            "Epoch 300/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 14486.8109 - mean_absolute_error: 14486.8109 - val_loss: 20903.3797 - val_mean_absolute_error: 20903.3797\n",
            "\n",
            "Epoch 00300: val_loss did not improve from 19612.33439\n",
            "Epoch 301/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 17779.6640 - mean_absolute_error: 17779.6640 - val_loss: 21235.0794 - val_mean_absolute_error: 21235.0794\n",
            "\n",
            "Epoch 00301: val_loss did not improve from 19612.33439\n",
            "Epoch 302/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 15363.2153 - mean_absolute_error: 15363.2153 - val_loss: 20440.2928 - val_mean_absolute_error: 20440.2928\n",
            "\n",
            "Epoch 00302: val_loss did not improve from 19612.33439\n",
            "Epoch 303/500\n",
            "1168/1168 [==============================] - 0s 290us/step - loss: 14174.6858 - mean_absolute_error: 14174.6858 - val_loss: 25900.6038 - val_mean_absolute_error: 25900.6038\n",
            "\n",
            "Epoch 00303: val_loss did not improve from 19612.33439\n",
            "Epoch 304/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 14325.6355 - mean_absolute_error: 14325.6355 - val_loss: 20004.3294 - val_mean_absolute_error: 20004.3294\n",
            "\n",
            "Epoch 00304: val_loss did not improve from 19612.33439\n",
            "Epoch 305/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 14055.5386 - mean_absolute_error: 14055.5386 - val_loss: 22681.5164 - val_mean_absolute_error: 22681.5164\n",
            "\n",
            "Epoch 00305: val_loss did not improve from 19612.33439\n",
            "Epoch 306/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 14035.1030 - mean_absolute_error: 14035.1030 - val_loss: 20883.2482 - val_mean_absolute_error: 20883.2482\n",
            "\n",
            "Epoch 00306: val_loss did not improve from 19612.33439\n",
            "Epoch 307/500\n",
            "1168/1168 [==============================] - 0s 303us/step - loss: 14551.1820 - mean_absolute_error: 14551.1820 - val_loss: 19584.1589 - val_mean_absolute_error: 19584.1589\n",
            "\n",
            "Epoch 00307: val_loss improved from 19612.33439 to 19584.15887, saving model to Weights-307--19584.15887.hdf5\n",
            "Epoch 308/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 14967.6378 - mean_absolute_error: 14967.6378 - val_loss: 20339.3761 - val_mean_absolute_error: 20339.3761\n",
            "\n",
            "Epoch 00308: val_loss did not improve from 19584.15887\n",
            "Epoch 309/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 14661.5261 - mean_absolute_error: 14661.5261 - val_loss: 20580.2652 - val_mean_absolute_error: 20580.2652\n",
            "\n",
            "Epoch 00309: val_loss did not improve from 19584.15887\n",
            "Epoch 310/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 15782.7783 - mean_absolute_error: 15782.7783 - val_loss: 20900.4901 - val_mean_absolute_error: 20900.4901\n",
            "\n",
            "Epoch 00310: val_loss did not improve from 19584.15887\n",
            "Epoch 311/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 15948.8501 - mean_absolute_error: 15948.8501 - val_loss: 21293.6112 - val_mean_absolute_error: 21293.6112\n",
            "\n",
            "Epoch 00311: val_loss did not improve from 19584.15887\n",
            "Epoch 312/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 15857.1290 - mean_absolute_error: 15857.1290 - val_loss: 19996.0301 - val_mean_absolute_error: 19996.0301\n",
            "\n",
            "Epoch 00312: val_loss did not improve from 19584.15887\n",
            "Epoch 313/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 16044.2329 - mean_absolute_error: 16044.2329 - val_loss: 21626.6797 - val_mean_absolute_error: 21626.6797\n",
            "\n",
            "Epoch 00313: val_loss did not improve from 19584.15887\n",
            "Epoch 314/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 15690.6188 - mean_absolute_error: 15690.6188 - val_loss: 20117.8820 - val_mean_absolute_error: 20117.8820\n",
            "\n",
            "Epoch 00314: val_loss did not improve from 19584.15887\n",
            "Epoch 315/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 15471.6535 - mean_absolute_error: 15471.6535 - val_loss: 22522.1778 - val_mean_absolute_error: 22522.1778\n",
            "\n",
            "Epoch 00315: val_loss did not improve from 19584.15887\n",
            "Epoch 316/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 14575.2044 - mean_absolute_error: 14575.2044 - val_loss: 23240.8319 - val_mean_absolute_error: 23240.8319\n",
            "\n",
            "Epoch 00316: val_loss did not improve from 19584.15887\n",
            "Epoch 317/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 15179.7433 - mean_absolute_error: 15179.7433 - val_loss: 21365.6413 - val_mean_absolute_error: 21365.6413\n",
            "\n",
            "Epoch 00317: val_loss did not improve from 19584.15887\n",
            "Epoch 318/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 15651.4953 - mean_absolute_error: 15651.4953 - val_loss: 20061.2727 - val_mean_absolute_error: 20061.2727\n",
            "\n",
            "Epoch 00318: val_loss did not improve from 19584.15887\n",
            "Epoch 319/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 14240.0975 - mean_absolute_error: 14240.0975 - val_loss: 20526.6720 - val_mean_absolute_error: 20526.6720\n",
            "\n",
            "Epoch 00319: val_loss did not improve from 19584.15887\n",
            "Epoch 320/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 14072.4685 - mean_absolute_error: 14072.4685 - val_loss: 20246.5452 - val_mean_absolute_error: 20246.5452\n",
            "\n",
            "Epoch 00320: val_loss did not improve from 19584.15887\n",
            "Epoch 321/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 14168.9447 - mean_absolute_error: 14168.9447 - val_loss: 20269.2407 - val_mean_absolute_error: 20269.2407\n",
            "\n",
            "Epoch 00321: val_loss did not improve from 19584.15887\n",
            "Epoch 322/500\n",
            "1168/1168 [==============================] - 0s 296us/step - loss: 14776.7065 - mean_absolute_error: 14776.7065 - val_loss: 22545.1361 - val_mean_absolute_error: 22545.1361\n",
            "\n",
            "Epoch 00322: val_loss did not improve from 19584.15887\n",
            "Epoch 323/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 14542.9858 - mean_absolute_error: 14542.9858 - val_loss: 20084.6070 - val_mean_absolute_error: 20084.6070\n",
            "\n",
            "Epoch 00323: val_loss did not improve from 19584.15887\n",
            "Epoch 324/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 15006.2303 - mean_absolute_error: 15006.2303 - val_loss: 26824.4499 - val_mean_absolute_error: 26824.4499\n",
            "\n",
            "Epoch 00324: val_loss did not improve from 19584.15887\n",
            "Epoch 325/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 15515.6211 - mean_absolute_error: 15515.6211 - val_loss: 23195.7608 - val_mean_absolute_error: 23195.7608\n",
            "\n",
            "Epoch 00325: val_loss did not improve from 19584.15887\n",
            "Epoch 326/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 16452.2811 - mean_absolute_error: 16452.2811 - val_loss: 21478.0604 - val_mean_absolute_error: 21478.0604\n",
            "\n",
            "Epoch 00326: val_loss did not improve from 19584.15887\n",
            "Epoch 327/500\n",
            "1168/1168 [==============================] - 0s 261us/step - loss: 14791.3401 - mean_absolute_error: 14791.3401 - val_loss: 20605.0363 - val_mean_absolute_error: 20605.0363\n",
            "\n",
            "Epoch 00327: val_loss did not improve from 19584.15887\n",
            "Epoch 328/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 13910.2371 - mean_absolute_error: 13910.2371 - val_loss: 20333.4681 - val_mean_absolute_error: 20333.4681\n",
            "\n",
            "Epoch 00328: val_loss did not improve from 19584.15887\n",
            "Epoch 329/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 15442.6390 - mean_absolute_error: 15442.6390 - val_loss: 21173.8016 - val_mean_absolute_error: 21173.8016\n",
            "\n",
            "Epoch 00329: val_loss did not improve from 19584.15887\n",
            "Epoch 330/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 14161.7380 - mean_absolute_error: 14161.7380 - val_loss: 19913.7850 - val_mean_absolute_error: 19913.7850\n",
            "\n",
            "Epoch 00330: val_loss did not improve from 19584.15887\n",
            "Epoch 331/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 14943.1652 - mean_absolute_error: 14943.1652 - val_loss: 24811.7417 - val_mean_absolute_error: 24811.7417\n",
            "\n",
            "Epoch 00331: val_loss did not improve from 19584.15887\n",
            "Epoch 332/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 14466.0535 - mean_absolute_error: 14466.0535 - val_loss: 19997.9488 - val_mean_absolute_error: 19997.9488\n",
            "\n",
            "Epoch 00332: val_loss did not improve from 19584.15887\n",
            "Epoch 333/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 15102.1710 - mean_absolute_error: 15102.1710 - val_loss: 20022.3155 - val_mean_absolute_error: 20022.3155\n",
            "\n",
            "Epoch 00333: val_loss did not improve from 19584.15887\n",
            "Epoch 334/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 13759.3518 - mean_absolute_error: 13759.3518 - val_loss: 20238.7535 - val_mean_absolute_error: 20238.7535\n",
            "\n",
            "Epoch 00334: val_loss did not improve from 19584.15887\n",
            "Epoch 335/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 14618.0062 - mean_absolute_error: 14618.0062 - val_loss: 20840.2264 - val_mean_absolute_error: 20840.2264\n",
            "\n",
            "Epoch 00335: val_loss did not improve from 19584.15887\n",
            "Epoch 336/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 15932.0518 - mean_absolute_error: 15932.0518 - val_loss: 20376.3883 - val_mean_absolute_error: 20376.3883\n",
            "\n",
            "Epoch 00336: val_loss did not improve from 19584.15887\n",
            "Epoch 337/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 15779.0164 - mean_absolute_error: 15779.0164 - val_loss: 21107.9788 - val_mean_absolute_error: 21107.9788\n",
            "\n",
            "Epoch 00337: val_loss did not improve from 19584.15887\n",
            "Epoch 338/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 15478.2522 - mean_absolute_error: 15478.2522 - val_loss: 22339.3512 - val_mean_absolute_error: 22339.3512\n",
            "\n",
            "Epoch 00338: val_loss did not improve from 19584.15887\n",
            "Epoch 339/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 16308.7196 - mean_absolute_error: 16308.7196 - val_loss: 21703.0696 - val_mean_absolute_error: 21703.0696\n",
            "\n",
            "Epoch 00339: val_loss did not improve from 19584.15887\n",
            "Epoch 340/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 14472.5764 - mean_absolute_error: 14472.5764 - val_loss: 20221.3976 - val_mean_absolute_error: 20221.3976\n",
            "\n",
            "Epoch 00340: val_loss did not improve from 19584.15887\n",
            "Epoch 341/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 14731.2688 - mean_absolute_error: 14731.2688 - val_loss: 20983.2239 - val_mean_absolute_error: 20983.2239\n",
            "\n",
            "Epoch 00341: val_loss did not improve from 19584.15887\n",
            "Epoch 342/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 13546.6167 - mean_absolute_error: 13546.6167 - val_loss: 24580.5679 - val_mean_absolute_error: 24580.5679\n",
            "\n",
            "Epoch 00342: val_loss did not improve from 19584.15887\n",
            "Epoch 343/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 14921.7592 - mean_absolute_error: 14921.7592 - val_loss: 19874.2784 - val_mean_absolute_error: 19874.2784\n",
            "\n",
            "Epoch 00343: val_loss did not improve from 19584.15887\n",
            "Epoch 344/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 14711.8030 - mean_absolute_error: 14711.8030 - val_loss: 20523.9904 - val_mean_absolute_error: 20523.9904\n",
            "\n",
            "Epoch 00344: val_loss did not improve from 19584.15887\n",
            "Epoch 345/500\n",
            "1168/1168 [==============================] - 0s 291us/step - loss: 14634.8094 - mean_absolute_error: 14634.8094 - val_loss: 21918.5626 - val_mean_absolute_error: 21918.5626\n",
            "\n",
            "Epoch 00345: val_loss did not improve from 19584.15887\n",
            "Epoch 346/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 17101.0311 - mean_absolute_error: 17101.0311 - val_loss: 24804.2960 - val_mean_absolute_error: 24804.2960\n",
            "\n",
            "Epoch 00346: val_loss did not improve from 19584.15887\n",
            "Epoch 347/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 13875.0360 - mean_absolute_error: 13875.0360 - val_loss: 20854.6617 - val_mean_absolute_error: 20854.6617\n",
            "\n",
            "Epoch 00347: val_loss did not improve from 19584.15887\n",
            "Epoch 348/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 13945.5917 - mean_absolute_error: 13945.5917 - val_loss: 22142.1135 - val_mean_absolute_error: 22142.1135\n",
            "\n",
            "Epoch 00348: val_loss did not improve from 19584.15887\n",
            "Epoch 349/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 15616.6411 - mean_absolute_error: 15616.6411 - val_loss: 22575.3376 - val_mean_absolute_error: 22575.3376\n",
            "\n",
            "Epoch 00349: val_loss did not improve from 19584.15887\n",
            "Epoch 350/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 16559.7349 - mean_absolute_error: 16559.7349 - val_loss: 20262.3789 - val_mean_absolute_error: 20262.3789\n",
            "\n",
            "Epoch 00350: val_loss did not improve from 19584.15887\n",
            "Epoch 351/500\n",
            "1168/1168 [==============================] - 0s 265us/step - loss: 14354.5144 - mean_absolute_error: 14354.5144 - val_loss: 22953.9490 - val_mean_absolute_error: 22953.9490\n",
            "\n",
            "Epoch 00351: val_loss did not improve from 19584.15887\n",
            "Epoch 352/500\n",
            "1168/1168 [==============================] - 0s 265us/step - loss: 16429.8564 - mean_absolute_error: 16429.8564 - val_loss: 20160.3335 - val_mean_absolute_error: 20160.3335\n",
            "\n",
            "Epoch 00352: val_loss did not improve from 19584.15887\n",
            "Epoch 353/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 14115.3643 - mean_absolute_error: 14115.3643 - val_loss: 22571.1906 - val_mean_absolute_error: 22571.1906\n",
            "\n",
            "Epoch 00353: val_loss did not improve from 19584.15887\n",
            "Epoch 354/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 14082.2917 - mean_absolute_error: 14082.2917 - val_loss: 19753.3028 - val_mean_absolute_error: 19753.3028\n",
            "\n",
            "Epoch 00354: val_loss did not improve from 19584.15887\n",
            "Epoch 355/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 14125.1354 - mean_absolute_error: 14125.1354 - val_loss: 20384.5135 - val_mean_absolute_error: 20384.5135\n",
            "\n",
            "Epoch 00355: val_loss did not improve from 19584.15887\n",
            "Epoch 356/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 13653.7251 - mean_absolute_error: 13653.7251 - val_loss: 22083.2024 - val_mean_absolute_error: 22083.2024\n",
            "\n",
            "Epoch 00356: val_loss did not improve from 19584.15887\n",
            "Epoch 357/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 15384.6551 - mean_absolute_error: 15384.6551 - val_loss: 20450.8854 - val_mean_absolute_error: 20450.8854\n",
            "\n",
            "Epoch 00357: val_loss did not improve from 19584.15887\n",
            "Epoch 358/500\n",
            "1168/1168 [==============================] - 0s 265us/step - loss: 13535.9237 - mean_absolute_error: 13535.9237 - val_loss: 22006.4499 - val_mean_absolute_error: 22006.4499\n",
            "\n",
            "Epoch 00358: val_loss did not improve from 19584.15887\n",
            "Epoch 359/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 13450.5024 - mean_absolute_error: 13450.5024 - val_loss: 20992.4338 - val_mean_absolute_error: 20992.4338\n",
            "\n",
            "Epoch 00359: val_loss did not improve from 19584.15887\n",
            "Epoch 360/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 14203.8645 - mean_absolute_error: 14203.8645 - val_loss: 20427.8844 - val_mean_absolute_error: 20427.8844\n",
            "\n",
            "Epoch 00360: val_loss did not improve from 19584.15887\n",
            "Epoch 361/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 14001.9421 - mean_absolute_error: 14001.9421 - val_loss: 20983.4278 - val_mean_absolute_error: 20983.4278\n",
            "\n",
            "Epoch 00361: val_loss did not improve from 19584.15887\n",
            "Epoch 362/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 14704.8262 - mean_absolute_error: 14704.8262 - val_loss: 19901.8280 - val_mean_absolute_error: 19901.8280\n",
            "\n",
            "Epoch 00362: val_loss did not improve from 19584.15887\n",
            "Epoch 363/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 13540.0827 - mean_absolute_error: 13540.0827 - val_loss: 21809.1335 - val_mean_absolute_error: 21809.1335\n",
            "\n",
            "Epoch 00363: val_loss did not improve from 19584.15887\n",
            "Epoch 364/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 14352.6819 - mean_absolute_error: 14352.6819 - val_loss: 19810.9331 - val_mean_absolute_error: 19810.9331\n",
            "\n",
            "Epoch 00364: val_loss did not improve from 19584.15887\n",
            "Epoch 365/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 15448.5639 - mean_absolute_error: 15448.5639 - val_loss: 20113.8601 - val_mean_absolute_error: 20113.8601\n",
            "\n",
            "Epoch 00365: val_loss did not improve from 19584.15887\n",
            "Epoch 366/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 14253.2910 - mean_absolute_error: 14253.2910 - val_loss: 24229.2909 - val_mean_absolute_error: 24229.2909\n",
            "\n",
            "Epoch 00366: val_loss did not improve from 19584.15887\n",
            "Epoch 367/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 14887.2514 - mean_absolute_error: 14887.2514 - val_loss: 20428.0250 - val_mean_absolute_error: 20428.0250\n",
            "\n",
            "Epoch 00367: val_loss did not improve from 19584.15887\n",
            "Epoch 368/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 13555.1633 - mean_absolute_error: 13555.1633 - val_loss: 20180.8390 - val_mean_absolute_error: 20180.8390\n",
            "\n",
            "Epoch 00368: val_loss did not improve from 19584.15887\n",
            "Epoch 369/500\n",
            "1168/1168 [==============================] - 0s 294us/step - loss: 16028.0829 - mean_absolute_error: 16028.0829 - val_loss: 23789.3586 - val_mean_absolute_error: 23789.3586\n",
            "\n",
            "Epoch 00369: val_loss did not improve from 19584.15887\n",
            "Epoch 370/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 15293.7263 - mean_absolute_error: 15293.7263 - val_loss: 20926.5106 - val_mean_absolute_error: 20926.5106\n",
            "\n",
            "Epoch 00370: val_loss did not improve from 19584.15887\n",
            "Epoch 371/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 13958.2045 - mean_absolute_error: 13958.2045 - val_loss: 19428.6316 - val_mean_absolute_error: 19428.6316\n",
            "\n",
            "Epoch 00371: val_loss improved from 19584.15887 to 19428.63164, saving model to Weights-371--19428.63164.hdf5\n",
            "Epoch 372/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 13695.5214 - mean_absolute_error: 13695.5214 - val_loss: 20408.7646 - val_mean_absolute_error: 20408.7646\n",
            "\n",
            "Epoch 00372: val_loss did not improve from 19428.63164\n",
            "Epoch 373/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 13496.8250 - mean_absolute_error: 13496.8250 - val_loss: 19400.4159 - val_mean_absolute_error: 19400.4159\n",
            "\n",
            "Epoch 00373: val_loss improved from 19428.63164 to 19400.41588, saving model to Weights-373--19400.41588.hdf5\n",
            "Epoch 374/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 14557.7305 - mean_absolute_error: 14557.7305 - val_loss: 20567.9848 - val_mean_absolute_error: 20567.9848\n",
            "\n",
            "Epoch 00374: val_loss did not improve from 19400.41588\n",
            "Epoch 375/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 14982.9089 - mean_absolute_error: 14982.9089 - val_loss: 20584.5292 - val_mean_absolute_error: 20584.5292\n",
            "\n",
            "Epoch 00375: val_loss did not improve from 19400.41588\n",
            "Epoch 376/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 14186.9093 - mean_absolute_error: 14186.9093 - val_loss: 20258.3665 - val_mean_absolute_error: 20258.3665\n",
            "\n",
            "Epoch 00376: val_loss did not improve from 19400.41588\n",
            "Epoch 377/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 14394.9222 - mean_absolute_error: 14394.9222 - val_loss: 22166.9183 - val_mean_absolute_error: 22166.9183\n",
            "\n",
            "Epoch 00377: val_loss did not improve from 19400.41588\n",
            "Epoch 378/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 16363.4012 - mean_absolute_error: 16363.4012 - val_loss: 20380.2220 - val_mean_absolute_error: 20380.2220\n",
            "\n",
            "Epoch 00378: val_loss did not improve from 19400.41588\n",
            "Epoch 379/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 14464.5874 - mean_absolute_error: 14464.5874 - val_loss: 19846.6371 - val_mean_absolute_error: 19846.6371\n",
            "\n",
            "Epoch 00379: val_loss did not improve from 19400.41588\n",
            "Epoch 380/500\n",
            "1168/1168 [==============================] - 0s 275us/step - loss: 13967.9037 - mean_absolute_error: 13967.9037 - val_loss: 23546.2842 - val_mean_absolute_error: 23546.2842\n",
            "\n",
            "Epoch 00380: val_loss did not improve from 19400.41588\n",
            "Epoch 381/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 14830.3192 - mean_absolute_error: 14830.3192 - val_loss: 21020.0479 - val_mean_absolute_error: 21020.0479\n",
            "\n",
            "Epoch 00381: val_loss did not improve from 19400.41588\n",
            "Epoch 382/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 16103.6035 - mean_absolute_error: 16103.6035 - val_loss: 23425.7390 - val_mean_absolute_error: 23425.7390\n",
            "\n",
            "Epoch 00382: val_loss did not improve from 19400.41588\n",
            "Epoch 383/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 15513.4162 - mean_absolute_error: 15513.4162 - val_loss: 20133.4185 - val_mean_absolute_error: 20133.4185\n",
            "\n",
            "Epoch 00383: val_loss did not improve from 19400.41588\n",
            "Epoch 384/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 13316.4605 - mean_absolute_error: 13316.4605 - val_loss: 19820.9988 - val_mean_absolute_error: 19820.9988\n",
            "\n",
            "Epoch 00384: val_loss did not improve from 19400.41588\n",
            "Epoch 385/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 14163.7387 - mean_absolute_error: 14163.7387 - val_loss: 20097.4090 - val_mean_absolute_error: 20097.4090\n",
            "\n",
            "Epoch 00385: val_loss did not improve from 19400.41588\n",
            "Epoch 386/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 13497.8034 - mean_absolute_error: 13497.8034 - val_loss: 21078.1230 - val_mean_absolute_error: 21078.1230\n",
            "\n",
            "Epoch 00386: val_loss did not improve from 19400.41588\n",
            "Epoch 387/500\n",
            "1168/1168 [==============================] - 0s 263us/step - loss: 14045.8613 - mean_absolute_error: 14045.8613 - val_loss: 20527.5966 - val_mean_absolute_error: 20527.5966\n",
            "\n",
            "Epoch 00387: val_loss did not improve from 19400.41588\n",
            "Epoch 388/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 13714.6992 - mean_absolute_error: 13714.6992 - val_loss: 20127.3989 - val_mean_absolute_error: 20127.3989\n",
            "\n",
            "Epoch 00388: val_loss did not improve from 19400.41588\n",
            "Epoch 389/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 15107.1268 - mean_absolute_error: 15107.1268 - val_loss: 25554.1639 - val_mean_absolute_error: 25554.1639\n",
            "\n",
            "Epoch 00389: val_loss did not improve from 19400.41588\n",
            "Epoch 390/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 16033.5786 - mean_absolute_error: 16033.5786 - val_loss: 20492.3015 - val_mean_absolute_error: 20492.3015\n",
            "\n",
            "Epoch 00390: val_loss did not improve from 19400.41588\n",
            "Epoch 391/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 13930.2024 - mean_absolute_error: 13930.2024 - val_loss: 20629.9146 - val_mean_absolute_error: 20629.9146\n",
            "\n",
            "Epoch 00391: val_loss did not improve from 19400.41588\n",
            "Epoch 392/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 14147.8827 - mean_absolute_error: 14147.8827 - val_loss: 20878.9837 - val_mean_absolute_error: 20878.9837\n",
            "\n",
            "Epoch 00392: val_loss did not improve from 19400.41588\n",
            "Epoch 393/500\n",
            "1168/1168 [==============================] - 0s 264us/step - loss: 14902.7343 - mean_absolute_error: 14902.7343 - val_loss: 20955.4399 - val_mean_absolute_error: 20955.4399\n",
            "\n",
            "Epoch 00393: val_loss did not improve from 19400.41588\n",
            "Epoch 394/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 14785.9738 - mean_absolute_error: 14785.9738 - val_loss: 22430.1337 - val_mean_absolute_error: 22430.1337\n",
            "\n",
            "Epoch 00394: val_loss did not improve from 19400.41588\n",
            "Epoch 395/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 13699.2911 - mean_absolute_error: 13699.2911 - val_loss: 20093.2145 - val_mean_absolute_error: 20093.2145\n",
            "\n",
            "Epoch 00395: val_loss did not improve from 19400.41588\n",
            "Epoch 396/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 16110.0126 - mean_absolute_error: 16110.0126 - val_loss: 20003.0320 - val_mean_absolute_error: 20003.0320\n",
            "\n",
            "Epoch 00396: val_loss did not improve from 19400.41588\n",
            "Epoch 397/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 15418.0166 - mean_absolute_error: 15418.0166 - val_loss: 20423.9025 - val_mean_absolute_error: 20423.9025\n",
            "\n",
            "Epoch 00397: val_loss did not improve from 19400.41588\n",
            "Epoch 398/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 16360.2269 - mean_absolute_error: 16360.2269 - val_loss: 22003.5213 - val_mean_absolute_error: 22003.5213\n",
            "\n",
            "Epoch 00398: val_loss did not improve from 19400.41588\n",
            "Epoch 399/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 14496.8942 - mean_absolute_error: 14496.8942 - val_loss: 21342.1721 - val_mean_absolute_error: 21342.1721\n",
            "\n",
            "Epoch 00399: val_loss did not improve from 19400.41588\n",
            "Epoch 400/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 13537.5006 - mean_absolute_error: 13537.5006 - val_loss: 20241.7436 - val_mean_absolute_error: 20241.7436\n",
            "\n",
            "Epoch 00400: val_loss did not improve from 19400.41588\n",
            "Epoch 401/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 15531.5709 - mean_absolute_error: 15531.5709 - val_loss: 19389.9687 - val_mean_absolute_error: 19389.9687\n",
            "\n",
            "Epoch 00401: val_loss improved from 19400.41588 to 19389.96870, saving model to Weights-401--19389.96870.hdf5\n",
            "Epoch 402/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 13473.3159 - mean_absolute_error: 13473.3159 - val_loss: 19208.3760 - val_mean_absolute_error: 19208.3760\n",
            "\n",
            "Epoch 00402: val_loss improved from 19389.96870 to 19208.37602, saving model to Weights-402--19208.37602.hdf5\n",
            "Epoch 403/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 15272.3900 - mean_absolute_error: 15272.3900 - val_loss: 20309.4335 - val_mean_absolute_error: 20309.4335\n",
            "\n",
            "Epoch 00403: val_loss did not improve from 19208.37602\n",
            "Epoch 404/500\n",
            "1168/1168 [==============================] - 0s 265us/step - loss: 13447.7707 - mean_absolute_error: 13447.7707 - val_loss: 20330.1866 - val_mean_absolute_error: 20330.1866\n",
            "\n",
            "Epoch 00404: val_loss did not improve from 19208.37602\n",
            "Epoch 405/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 14958.4104 - mean_absolute_error: 14958.4104 - val_loss: 20100.6865 - val_mean_absolute_error: 20100.6865\n",
            "\n",
            "Epoch 00405: val_loss did not improve from 19208.37602\n",
            "Epoch 406/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 18000.2698 - mean_absolute_error: 18000.2698 - val_loss: 23347.5675 - val_mean_absolute_error: 23347.5675\n",
            "\n",
            "Epoch 00406: val_loss did not improve from 19208.37602\n",
            "Epoch 407/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 15029.9654 - mean_absolute_error: 15029.9654 - val_loss: 19656.7083 - val_mean_absolute_error: 19656.7083\n",
            "\n",
            "Epoch 00407: val_loss did not improve from 19208.37602\n",
            "Epoch 408/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 14852.5406 - mean_absolute_error: 14852.5406 - val_loss: 20429.7874 - val_mean_absolute_error: 20429.7874\n",
            "\n",
            "Epoch 00408: val_loss did not improve from 19208.37602\n",
            "Epoch 409/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 14703.7152 - mean_absolute_error: 14703.7152 - val_loss: 23424.7779 - val_mean_absolute_error: 23424.7779\n",
            "\n",
            "Epoch 00409: val_loss did not improve from 19208.37602\n",
            "Epoch 410/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 17417.3884 - mean_absolute_error: 17417.3884 - val_loss: 23134.5734 - val_mean_absolute_error: 23134.5734\n",
            "\n",
            "Epoch 00410: val_loss did not improve from 19208.37602\n",
            "Epoch 411/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 14924.2075 - mean_absolute_error: 14924.2075 - val_loss: 19631.3825 - val_mean_absolute_error: 19631.3825\n",
            "\n",
            "Epoch 00411: val_loss did not improve from 19208.37602\n",
            "Epoch 412/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 13467.1883 - mean_absolute_error: 13467.1883 - val_loss: 22513.8509 - val_mean_absolute_error: 22513.8509\n",
            "\n",
            "Epoch 00412: val_loss did not improve from 19208.37602\n",
            "Epoch 413/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 14077.8291 - mean_absolute_error: 14077.8291 - val_loss: 19225.6643 - val_mean_absolute_error: 19225.6643\n",
            "\n",
            "Epoch 00413: val_loss did not improve from 19208.37602\n",
            "Epoch 414/500\n",
            "1168/1168 [==============================] - 0s 279us/step - loss: 13399.6604 - mean_absolute_error: 13399.6604 - val_loss: 20499.4332 - val_mean_absolute_error: 20499.4332\n",
            "\n",
            "Epoch 00414: val_loss did not improve from 19208.37602\n",
            "Epoch 415/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 13572.6020 - mean_absolute_error: 13572.6020 - val_loss: 20254.3774 - val_mean_absolute_error: 20254.3774\n",
            "\n",
            "Epoch 00415: val_loss did not improve from 19208.37602\n",
            "Epoch 416/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 13528.6555 - mean_absolute_error: 13528.6555 - val_loss: 22525.7531 - val_mean_absolute_error: 22525.7531\n",
            "\n",
            "Epoch 00416: val_loss did not improve from 19208.37602\n",
            "Epoch 417/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 14456.1305 - mean_absolute_error: 14456.1305 - val_loss: 20398.2437 - val_mean_absolute_error: 20398.2437\n",
            "\n",
            "Epoch 00417: val_loss did not improve from 19208.37602\n",
            "Epoch 418/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 13469.8860 - mean_absolute_error: 13469.8860 - val_loss: 21823.6214 - val_mean_absolute_error: 21823.6214\n",
            "\n",
            "Epoch 00418: val_loss did not improve from 19208.37602\n",
            "Epoch 419/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 13846.0846 - mean_absolute_error: 13846.0846 - val_loss: 20276.5682 - val_mean_absolute_error: 20276.5682\n",
            "\n",
            "Epoch 00419: val_loss did not improve from 19208.37602\n",
            "Epoch 420/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 14413.5657 - mean_absolute_error: 14413.5657 - val_loss: 19900.4336 - val_mean_absolute_error: 19900.4336\n",
            "\n",
            "Epoch 00420: val_loss did not improve from 19208.37602\n",
            "Epoch 421/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 14642.5287 - mean_absolute_error: 14642.5287 - val_loss: 19558.2775 - val_mean_absolute_error: 19558.2775\n",
            "\n",
            "Epoch 00421: val_loss did not improve from 19208.37602\n",
            "Epoch 422/500\n",
            "1168/1168 [==============================] - 0s 293us/step - loss: 14226.9870 - mean_absolute_error: 14226.9870 - val_loss: 19577.8768 - val_mean_absolute_error: 19577.8768\n",
            "\n",
            "Epoch 00422: val_loss did not improve from 19208.37602\n",
            "Epoch 423/500\n",
            "1168/1168 [==============================] - 0s 271us/step - loss: 12941.5989 - mean_absolute_error: 12941.5989 - val_loss: 19556.3405 - val_mean_absolute_error: 19556.3405\n",
            "\n",
            "Epoch 00423: val_loss did not improve from 19208.37602\n",
            "Epoch 424/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 13492.1960 - mean_absolute_error: 13492.1960 - val_loss: 21219.2810 - val_mean_absolute_error: 21219.2810\n",
            "\n",
            "Epoch 00424: val_loss did not improve from 19208.37602\n",
            "Epoch 425/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 13126.2152 - mean_absolute_error: 13126.2152 - val_loss: 21185.1595 - val_mean_absolute_error: 21185.1595\n",
            "\n",
            "Epoch 00425: val_loss did not improve from 19208.37602\n",
            "Epoch 426/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 14332.6881 - mean_absolute_error: 14332.6881 - val_loss: 21404.6885 - val_mean_absolute_error: 21404.6885\n",
            "\n",
            "Epoch 00426: val_loss did not improve from 19208.37602\n",
            "Epoch 427/500\n",
            "1168/1168 [==============================] - 0s 276us/step - loss: 13830.8209 - mean_absolute_error: 13830.8209 - val_loss: 20981.7132 - val_mean_absolute_error: 20981.7132\n",
            "\n",
            "Epoch 00427: val_loss did not improve from 19208.37602\n",
            "Epoch 428/500\n",
            "1168/1168 [==============================] - 0s 262us/step - loss: 14163.1132 - mean_absolute_error: 14163.1132 - val_loss: 20705.1449 - val_mean_absolute_error: 20705.1449\n",
            "\n",
            "Epoch 00428: val_loss did not improve from 19208.37602\n",
            "Epoch 429/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 13791.6599 - mean_absolute_error: 13791.6599 - val_loss: 19659.6773 - val_mean_absolute_error: 19659.6773\n",
            "\n",
            "Epoch 00429: val_loss did not improve from 19208.37602\n",
            "Epoch 430/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 13155.8507 - mean_absolute_error: 13155.8507 - val_loss: 22650.6856 - val_mean_absolute_error: 22650.6856\n",
            "\n",
            "Epoch 00430: val_loss did not improve from 19208.37602\n",
            "Epoch 431/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 14567.7064 - mean_absolute_error: 14567.7064 - val_loss: 19725.9532 - val_mean_absolute_error: 19725.9532\n",
            "\n",
            "Epoch 00431: val_loss did not improve from 19208.37602\n",
            "Epoch 432/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 13082.9449 - mean_absolute_error: 13082.9449 - val_loss: 19891.3500 - val_mean_absolute_error: 19891.3500\n",
            "\n",
            "Epoch 00432: val_loss did not improve from 19208.37602\n",
            "Epoch 433/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 13168.1864 - mean_absolute_error: 13168.1864 - val_loss: 20970.0897 - val_mean_absolute_error: 20970.0897\n",
            "\n",
            "Epoch 00433: val_loss did not improve from 19208.37602\n",
            "Epoch 434/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 16260.3554 - mean_absolute_error: 16260.3554 - val_loss: 20577.2772 - val_mean_absolute_error: 20577.2772\n",
            "\n",
            "Epoch 00434: val_loss did not improve from 19208.37602\n",
            "Epoch 435/500\n",
            "1168/1168 [==============================] - 0s 273us/step - loss: 13924.2273 - mean_absolute_error: 13924.2273 - val_loss: 23142.4330 - val_mean_absolute_error: 23142.4330\n",
            "\n",
            "Epoch 00435: val_loss did not improve from 19208.37602\n",
            "Epoch 436/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 12646.4428 - mean_absolute_error: 12646.4428 - val_loss: 20699.9553 - val_mean_absolute_error: 20699.9553\n",
            "\n",
            "Epoch 00436: val_loss did not improve from 19208.37602\n",
            "Epoch 437/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 14275.7592 - mean_absolute_error: 14275.7592 - val_loss: 19805.1702 - val_mean_absolute_error: 19805.1702\n",
            "\n",
            "Epoch 00437: val_loss did not improve from 19208.37602\n",
            "Epoch 438/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 13094.3919 - mean_absolute_error: 13094.3919 - val_loss: 19886.0045 - val_mean_absolute_error: 19886.0045\n",
            "\n",
            "Epoch 00438: val_loss did not improve from 19208.37602\n",
            "Epoch 439/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 14072.5933 - mean_absolute_error: 14072.5933 - val_loss: 20616.1161 - val_mean_absolute_error: 20616.1161\n",
            "\n",
            "Epoch 00439: val_loss did not improve from 19208.37602\n",
            "Epoch 440/500\n",
            "1168/1168 [==============================] - 0s 266us/step - loss: 14506.7868 - mean_absolute_error: 14506.7868 - val_loss: 20562.7467 - val_mean_absolute_error: 20562.7467\n",
            "\n",
            "Epoch 00440: val_loss did not improve from 19208.37602\n",
            "Epoch 441/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 13786.7019 - mean_absolute_error: 13786.7019 - val_loss: 19579.2377 - val_mean_absolute_error: 19579.2377\n",
            "\n",
            "Epoch 00441: val_loss did not improve from 19208.37602\n",
            "Epoch 442/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 13695.9020 - mean_absolute_error: 13695.9020 - val_loss: 22121.7791 - val_mean_absolute_error: 22121.7791\n",
            "\n",
            "Epoch 00442: val_loss did not improve from 19208.37602\n",
            "Epoch 443/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 12847.6501 - mean_absolute_error: 12847.6501 - val_loss: 25524.9631 - val_mean_absolute_error: 25524.9631\n",
            "\n",
            "Epoch 00443: val_loss did not improve from 19208.37602\n",
            "Epoch 444/500\n",
            "1168/1168 [==============================] - 0s 274us/step - loss: 14122.7198 - mean_absolute_error: 14122.7198 - val_loss: 21033.7252 - val_mean_absolute_error: 21033.7252\n",
            "\n",
            "Epoch 00444: val_loss did not improve from 19208.37602\n",
            "Epoch 445/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 13186.2968 - mean_absolute_error: 13186.2968 - val_loss: 20618.2891 - val_mean_absolute_error: 20618.2891\n",
            "\n",
            "Epoch 00445: val_loss did not improve from 19208.37602\n",
            "Epoch 446/500\n",
            "1168/1168 [==============================] - 0s 295us/step - loss: 14302.0938 - mean_absolute_error: 14302.0938 - val_loss: 20008.5853 - val_mean_absolute_error: 20008.5853\n",
            "\n",
            "Epoch 00446: val_loss did not improve from 19208.37602\n",
            "Epoch 447/500\n",
            "1168/1168 [==============================] - 0s 291us/step - loss: 15482.2166 - mean_absolute_error: 15482.2166 - val_loss: 20743.1924 - val_mean_absolute_error: 20743.1924\n",
            "\n",
            "Epoch 00447: val_loss did not improve from 19208.37602\n",
            "Epoch 448/500\n",
            "1168/1168 [==============================] - 0s 293us/step - loss: 14629.5492 - mean_absolute_error: 14629.5492 - val_loss: 24276.5735 - val_mean_absolute_error: 24276.5735\n",
            "\n",
            "Epoch 00448: val_loss did not improve from 19208.37602\n",
            "Epoch 449/500\n",
            "1168/1168 [==============================] - 0s 304us/step - loss: 15210.3015 - mean_absolute_error: 15210.3015 - val_loss: 19405.3525 - val_mean_absolute_error: 19405.3525\n",
            "\n",
            "Epoch 00449: val_loss did not improve from 19208.37602\n",
            "Epoch 450/500\n",
            "1168/1168 [==============================] - 0s 285us/step - loss: 13288.4255 - mean_absolute_error: 13288.4255 - val_loss: 21802.0165 - val_mean_absolute_error: 21802.0165\n",
            "\n",
            "Epoch 00450: val_loss did not improve from 19208.37602\n",
            "Epoch 451/500\n",
            "1168/1168 [==============================] - 0s 297us/step - loss: 15819.9218 - mean_absolute_error: 15819.9218 - val_loss: 21792.9160 - val_mean_absolute_error: 21792.9160\n",
            "\n",
            "Epoch 00451: val_loss did not improve from 19208.37602\n",
            "Epoch 452/500\n",
            "1168/1168 [==============================] - 0s 290us/step - loss: 13801.4511 - mean_absolute_error: 13801.4511 - val_loss: 22025.0283 - val_mean_absolute_error: 22025.0283\n",
            "\n",
            "Epoch 00452: val_loss did not improve from 19208.37602\n",
            "Epoch 453/500\n",
            "1168/1168 [==============================] - 0s 305us/step - loss: 13291.7184 - mean_absolute_error: 13291.7184 - val_loss: 20634.1368 - val_mean_absolute_error: 20634.1368\n",
            "\n",
            "Epoch 00453: val_loss did not improve from 19208.37602\n",
            "Epoch 454/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 13444.7657 - mean_absolute_error: 13444.7657 - val_loss: 19479.8297 - val_mean_absolute_error: 19479.8297\n",
            "\n",
            "Epoch 00454: val_loss did not improve from 19208.37602\n",
            "Epoch 455/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 13656.8913 - mean_absolute_error: 13656.8913 - val_loss: 24256.3626 - val_mean_absolute_error: 24256.3626\n",
            "\n",
            "Epoch 00455: val_loss did not improve from 19208.37602\n",
            "Epoch 456/500\n",
            "1168/1168 [==============================] - 0s 293us/step - loss: 14515.7051 - mean_absolute_error: 14515.7051 - val_loss: 20443.0364 - val_mean_absolute_error: 20443.0364\n",
            "\n",
            "Epoch 00456: val_loss did not improve from 19208.37602\n",
            "Epoch 457/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 13544.6685 - mean_absolute_error: 13544.6685 - val_loss: 22733.0535 - val_mean_absolute_error: 22733.0535\n",
            "\n",
            "Epoch 00457: val_loss did not improve from 19208.37602\n",
            "Epoch 458/500\n",
            "1168/1168 [==============================] - 0s 288us/step - loss: 13775.9381 - mean_absolute_error: 13775.9381 - val_loss: 20348.3513 - val_mean_absolute_error: 20348.3513\n",
            "\n",
            "Epoch 00458: val_loss did not improve from 19208.37602\n",
            "Epoch 459/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 14285.1205 - mean_absolute_error: 14285.1205 - val_loss: 20357.5783 - val_mean_absolute_error: 20357.5783\n",
            "\n",
            "Epoch 00459: val_loss did not improve from 19208.37602\n",
            "Epoch 460/500\n",
            "1168/1168 [==============================] - 0s 302us/step - loss: 13519.9792 - mean_absolute_error: 13519.9792 - val_loss: 19387.7982 - val_mean_absolute_error: 19387.7982\n",
            "\n",
            "Epoch 00460: val_loss did not improve from 19208.37602\n",
            "Epoch 461/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 12874.5556 - mean_absolute_error: 12874.5556 - val_loss: 19588.8554 - val_mean_absolute_error: 19588.8554\n",
            "\n",
            "Epoch 00461: val_loss did not improve from 19208.37602\n",
            "Epoch 462/500\n",
            "1168/1168 [==============================] - 0s 278us/step - loss: 12871.6755 - mean_absolute_error: 12871.6755 - val_loss: 20331.3554 - val_mean_absolute_error: 20331.3554\n",
            "\n",
            "Epoch 00462: val_loss did not improve from 19208.37602\n",
            "Epoch 463/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 15292.8401 - mean_absolute_error: 15292.8401 - val_loss: 21052.0645 - val_mean_absolute_error: 21052.0645\n",
            "\n",
            "Epoch 00463: val_loss did not improve from 19208.37602\n",
            "Epoch 464/500\n",
            "1168/1168 [==============================] - 0s 307us/step - loss: 14190.7074 - mean_absolute_error: 14190.7074 - val_loss: 19728.5853 - val_mean_absolute_error: 19728.5853\n",
            "\n",
            "Epoch 00464: val_loss did not improve from 19208.37602\n",
            "Epoch 465/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 12928.1493 - mean_absolute_error: 12928.1493 - val_loss: 20523.7826 - val_mean_absolute_error: 20523.7826\n",
            "\n",
            "Epoch 00465: val_loss did not improve from 19208.37602\n",
            "Epoch 466/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 12845.1309 - mean_absolute_error: 12845.1309 - val_loss: 20780.9060 - val_mean_absolute_error: 20780.9060\n",
            "\n",
            "Epoch 00466: val_loss did not improve from 19208.37602\n",
            "Epoch 467/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 13397.7289 - mean_absolute_error: 13397.7289 - val_loss: 20741.4851 - val_mean_absolute_error: 20741.4851\n",
            "\n",
            "Epoch 00467: val_loss did not improve from 19208.37602\n",
            "Epoch 468/500\n",
            "1168/1168 [==============================] - 0s 298us/step - loss: 13805.8884 - mean_absolute_error: 13805.8884 - val_loss: 21042.0779 - val_mean_absolute_error: 21042.0779\n",
            "\n",
            "Epoch 00468: val_loss did not improve from 19208.37602\n",
            "Epoch 469/500\n",
            "1168/1168 [==============================] - 0s 280us/step - loss: 14343.4288 - mean_absolute_error: 14343.4288 - val_loss: 22833.8461 - val_mean_absolute_error: 22833.8461\n",
            "\n",
            "Epoch 00469: val_loss did not improve from 19208.37602\n",
            "Epoch 470/500\n",
            "1168/1168 [==============================] - 0s 286us/step - loss: 13936.7023 - mean_absolute_error: 13936.7023 - val_loss: 21974.0780 - val_mean_absolute_error: 21974.0780\n",
            "\n",
            "Epoch 00470: val_loss did not improve from 19208.37602\n",
            "Epoch 471/500\n",
            "1168/1168 [==============================] - 0s 300us/step - loss: 15545.7745 - mean_absolute_error: 15545.7745 - val_loss: 20457.9120 - val_mean_absolute_error: 20457.9120\n",
            "\n",
            "Epoch 00471: val_loss did not improve from 19208.37602\n",
            "Epoch 472/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 12665.8690 - mean_absolute_error: 12665.8690 - val_loss: 24737.0241 - val_mean_absolute_error: 24737.0241\n",
            "\n",
            "Epoch 00472: val_loss did not improve from 19208.37602\n",
            "Epoch 473/500\n",
            "1168/1168 [==============================] - 0s 282us/step - loss: 14129.3956 - mean_absolute_error: 14129.3956 - val_loss: 21604.4346 - val_mean_absolute_error: 21604.4346\n",
            "\n",
            "Epoch 00473: val_loss did not improve from 19208.37602\n",
            "Epoch 474/500\n",
            "1168/1168 [==============================] - 0s 289us/step - loss: 14550.5843 - mean_absolute_error: 14550.5843 - val_loss: 21998.5462 - val_mean_absolute_error: 21998.5462\n",
            "\n",
            "Epoch 00474: val_loss did not improve from 19208.37602\n",
            "Epoch 475/500\n",
            "1168/1168 [==============================] - 0s 288us/step - loss: 13286.5127 - mean_absolute_error: 13286.5127 - val_loss: 19829.5430 - val_mean_absolute_error: 19829.5430\n",
            "\n",
            "Epoch 00475: val_loss did not improve from 19208.37602\n",
            "Epoch 476/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 13292.7352 - mean_absolute_error: 13292.7352 - val_loss: 21014.5711 - val_mean_absolute_error: 21014.5711\n",
            "\n",
            "Epoch 00476: val_loss did not improve from 19208.37602\n",
            "Epoch 477/500\n",
            "1168/1168 [==============================] - 0s 287us/step - loss: 14466.6263 - mean_absolute_error: 14466.6263 - val_loss: 22300.8240 - val_mean_absolute_error: 22300.8240\n",
            "\n",
            "Epoch 00477: val_loss did not improve from 19208.37602\n",
            "Epoch 478/500\n",
            "1168/1168 [==============================] - 0s 306us/step - loss: 14879.6585 - mean_absolute_error: 14879.6585 - val_loss: 18738.1983 - val_mean_absolute_error: 18738.1983\n",
            "\n",
            "Epoch 00478: val_loss improved from 19208.37602 to 18738.19831, saving model to Weights-478--18738.19831.hdf5\n",
            "Epoch 479/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 14910.1849 - mean_absolute_error: 14910.1849 - val_loss: 23107.6234 - val_mean_absolute_error: 23107.6234\n",
            "\n",
            "Epoch 00479: val_loss did not improve from 18738.19831\n",
            "Epoch 480/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 15663.1485 - mean_absolute_error: 15663.1485 - val_loss: 19569.6311 - val_mean_absolute_error: 19569.6311\n",
            "\n",
            "Epoch 00480: val_loss did not improve from 18738.19831\n",
            "Epoch 481/500\n",
            "1168/1168 [==============================] - 0s 277us/step - loss: 12387.6448 - mean_absolute_error: 12387.6448 - val_loss: 19620.8434 - val_mean_absolute_error: 19620.8434\n",
            "\n",
            "Epoch 00481: val_loss did not improve from 18738.19831\n",
            "Epoch 482/500\n",
            "1168/1168 [==============================] - 0s 302us/step - loss: 13738.3240 - mean_absolute_error: 13738.3240 - val_loss: 20539.6847 - val_mean_absolute_error: 20539.6847\n",
            "\n",
            "Epoch 00482: val_loss did not improve from 18738.19831\n",
            "Epoch 483/500\n",
            "1168/1168 [==============================] - 0s 294us/step - loss: 14231.5559 - mean_absolute_error: 14231.5559 - val_loss: 19389.9292 - val_mean_absolute_error: 19389.9292\n",
            "\n",
            "Epoch 00483: val_loss did not improve from 18738.19831\n",
            "Epoch 484/500\n",
            "1168/1168 [==============================] - 0s 291us/step - loss: 13512.3584 - mean_absolute_error: 13512.3584 - val_loss: 20085.0206 - val_mean_absolute_error: 20085.0206\n",
            "\n",
            "Epoch 00484: val_loss did not improve from 18738.19831\n",
            "Epoch 485/500\n",
            "1168/1168 [==============================] - 0s 288us/step - loss: 14186.3182 - mean_absolute_error: 14186.3182 - val_loss: 22271.9279 - val_mean_absolute_error: 22271.9279\n",
            "\n",
            "Epoch 00485: val_loss did not improve from 18738.19831\n",
            "Epoch 486/500\n",
            "1168/1168 [==============================] - 0s 310us/step - loss: 13177.8550 - mean_absolute_error: 13177.8550 - val_loss: 20226.5321 - val_mean_absolute_error: 20226.5321\n",
            "\n",
            "Epoch 00486: val_loss did not improve from 18738.19831\n",
            "Epoch 487/500\n",
            "1168/1168 [==============================] - 0s 288us/step - loss: 14108.8349 - mean_absolute_error: 14108.8349 - val_loss: 19832.5933 - val_mean_absolute_error: 19832.5933\n",
            "\n",
            "Epoch 00487: val_loss did not improve from 18738.19831\n",
            "Epoch 488/500\n",
            "1168/1168 [==============================] - 0s 294us/step - loss: 13644.1840 - mean_absolute_error: 13644.1840 - val_loss: 20636.6926 - val_mean_absolute_error: 20636.6926\n",
            "\n",
            "Epoch 00488: val_loss did not improve from 18738.19831\n",
            "Epoch 489/500\n",
            "1168/1168 [==============================] - 0s 283us/step - loss: 13231.7564 - mean_absolute_error: 13231.7564 - val_loss: 19627.0708 - val_mean_absolute_error: 19627.0708\n",
            "\n",
            "Epoch 00489: val_loss did not improve from 18738.19831\n",
            "Epoch 490/500\n",
            "1168/1168 [==============================] - 0s 284us/step - loss: 13347.1915 - mean_absolute_error: 13347.1915 - val_loss: 19787.5036 - val_mean_absolute_error: 19787.5036\n",
            "\n",
            "Epoch 00490: val_loss did not improve from 18738.19831\n",
            "Epoch 491/500\n",
            "1168/1168 [==============================] - 0s 272us/step - loss: 12817.9035 - mean_absolute_error: 12817.9035 - val_loss: 19219.7795 - val_mean_absolute_error: 19219.7795\n",
            "\n",
            "Epoch 00491: val_loss did not improve from 18738.19831\n",
            "Epoch 492/500\n",
            "1168/1168 [==============================] - 0s 264us/step - loss: 13500.8851 - mean_absolute_error: 13500.8851 - val_loss: 19293.4248 - val_mean_absolute_error: 19293.4248\n",
            "\n",
            "Epoch 00492: val_loss did not improve from 18738.19831\n",
            "Epoch 493/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 14092.6717 - mean_absolute_error: 14092.6717 - val_loss: 20169.6081 - val_mean_absolute_error: 20169.6081\n",
            "\n",
            "Epoch 00493: val_loss did not improve from 18738.19831\n",
            "Epoch 494/500\n",
            "1168/1168 [==============================] - 0s 268us/step - loss: 13011.5806 - mean_absolute_error: 13011.5806 - val_loss: 23483.0771 - val_mean_absolute_error: 23483.0771\n",
            "\n",
            "Epoch 00494: val_loss did not improve from 18738.19831\n",
            "Epoch 495/500\n",
            "1168/1168 [==============================] - 0s 270us/step - loss: 12746.9208 - mean_absolute_error: 12746.9208 - val_loss: 22781.2117 - val_mean_absolute_error: 22781.2117\n",
            "\n",
            "Epoch 00495: val_loss did not improve from 18738.19831\n",
            "Epoch 496/500\n",
            "1168/1168 [==============================] - 0s 263us/step - loss: 13743.9191 - mean_absolute_error: 13743.9191 - val_loss: 20729.2135 - val_mean_absolute_error: 20729.2135\n",
            "\n",
            "Epoch 00496: val_loss did not improve from 18738.19831\n",
            "Epoch 497/500\n",
            "1168/1168 [==============================] - 0s 281us/step - loss: 12998.8823 - mean_absolute_error: 12998.8823 - val_loss: 19692.0106 - val_mean_absolute_error: 19692.0106\n",
            "\n",
            "Epoch 00497: val_loss did not improve from 18738.19831\n",
            "Epoch 498/500\n",
            "1168/1168 [==============================] - 0s 264us/step - loss: 13209.7730 - mean_absolute_error: 13209.7730 - val_loss: 20249.0203 - val_mean_absolute_error: 20249.0203\n",
            "\n",
            "Epoch 00498: val_loss did not improve from 18738.19831\n",
            "Epoch 499/500\n",
            "1168/1168 [==============================] - 0s 267us/step - loss: 12730.9457 - mean_absolute_error: 12730.9457 - val_loss: 19223.3638 - val_mean_absolute_error: 19223.3638\n",
            "\n",
            "Epoch 00499: val_loss did not improve from 18738.19831\n",
            "Epoch 500/500\n",
            "1168/1168 [==============================] - 0s 269us/step - loss: 13027.5740 - mean_absolute_error: 13027.5740 - val_loss: 19731.3621 - val_mean_absolute_error: 19731.3621\n",
            "\n",
            "Epoch 00500: val_loss did not improve from 18738.19831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4324aa80b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7waTYZD9QDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load wights file of the best model :\n",
        "wights_file = 'Weights-478--18738.19831.hdf5' # choose the best checkpoint \n",
        "NN_model.load_weights(wights_file) # load it\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}